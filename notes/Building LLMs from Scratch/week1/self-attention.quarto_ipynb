{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"EXERCISE: Self-Attention\"\n",
        "categories: Building LLMs from Scratch\n",
        "date: 05-25-2025\n",
        "---\n",
        "\n",
        "\n",
        "# Self-Attention\n",
        "\n",
        "Welcome to the first exercise in our Building LLMs from Scratch series! In this exercise, we'll dive into the core concept of self-attention, which is the foundation of modern transformer-based models.\n",
        "\n",
        "## ðŸ“š Learning Path:\n"
      ],
      "id": "9617dcf9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d_in: int, d_out: int):\n",
        "        super().__init__()\n",
        "        # d_in: Input dimension - the size of each input embedding/feature vector\n",
        "        self.d_in = d_in\n",
        "        # d_out: Output dimension - the desired size of the attention output\n",
        "        self.d_out = d_out\n",
        "\n",
        "        # Linear transformation layers for generating queries, keys, and values\n",
        "        # q: Query projection - transforms input to query space for \"what am I looking for?\"\n",
        "        self.q = nn.Linear(d_in, d_out)\n",
        "        # k: Key projection - transforms input to key space for \"what information do I contain?\"\n",
        "        self.k = nn.Linear(d_in, d_out)\n",
        "        # v: Value projection - transforms input to value space for \"what information should I output?\"\n",
        "        self.v = nn.Linear(d_in, d_out)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: Input tensor of shape (batch_size, sequence_length, d_in)\n",
        "        # Generate query vectors - represent what each position is \"looking for\"\n",
        "        q = self.q(x)\n",
        "        # Generate key vectors - represent what information each position \"contains\"\n",
        "        k = self.k(x)\n",
        "        # Generate value vectors - represent the actual information to be aggregated\n",
        "        v = self.v(x)\n",
        "\n",
        "        # Calculate attention scores - how much each position is relevant to each other\n",
        "        scores = torch.bmm(q, k.transpose(1, 2)) / torch.sqrt(torch.tensor(self.d_out))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        # Apply attention weights to value vectors to get aggregated output\n",
        "        hidden_states = torch.bmm(attn_weights, v)\n",
        "        return hidden_states"
      ],
      "id": "3f5c644c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's add the SOS token to the input and EOT token to the output.\n"
      ],
      "id": "c89327f5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SOS_TOKEN = \"<SOS>\"\n",
        "EOT_TOKEN = \"<EOT>\"\n",
        "\n",
        "words = [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"]"
      ],
      "id": "224ea63a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Index mapping for the words\n"
      ],
      "id": "4cc019e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_set_idx = {i: word for i, word in enumerate(words + [SOS_TOKEN, EOT_TOKEN])}\n",
        "\n",
        "print(word_set_idx)"
      ],
      "id": "e2671b12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's invert the map to have keys be the words and values be the indices.\n"
      ],
      "id": "aef2f851"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(words + [SOS_TOKEN, EOT_TOKEN])}\n",
        "\n",
        "print(word_to_ix)"
      ],
      "id": "5471a68d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a helper function to convert a list of words to a tensor of input tokens.\n"
      ],
      "id": "10733528"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def convert_words_to_tensors(words: list[str]) -> torch.Tensor:\n",
        "    return torch.tensor([word_to_ix[word] for word in words], dtype=torch.long).view(-1, 1)"
      ],
      "id": "79c807f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a helper function to convert a tensor of input tokens to a list of words.\n"
      ],
      "id": "83a56f10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def convert_tensors_to_words(tensors: torch.Tensor) -> list[str]:\n",
        "    return [word_set_idx[i] for i in tensors]"
      ],
      "id": "c03aa386",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}