{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"EXERCISE: XGBoost\"\n",
        "categories: Machine Learning\n",
        "date: 05-22-2025\n",
        "---\n",
        "\n",
        "\n",
        "# XGBoost: A Complete Learning Journey\n",
        "\n",
        "Welcome to this comprehensive tutorial on XGBoost! This notebook is designed to take you from zero knowledge to building real-world models.\n",
        "\n",
        "## ðŸ“š Learning Path:\n",
        "\n",
        "**Part 1: Foundations (Theory & Practice)**\n",
        "- Lesson 1: What is Machine Learning Boosting?\n",
        "- Lesson 2: Understanding Decision Trees\n",
        "- Lesson 3: From Trees to Ensemble Methods\n",
        "- Lesson 4: Gradient Boosting Explained\n",
        "- Lesson 5: Enter XGBoost\n",
        "- Lesson 6: XGBoost Parameters Deep Dive\n",
        "- Lesson 7: Preventing Overfitting\n",
        "\n",
        "**Part 2: Hands-On Project**\n",
        "- Building a Complete Credit Risk Model\n",
        "\n",
        "## ðŸš€ Let's Start: Setting Up Our Environment\n"
      ],
      "id": "28cefd06"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import all necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up visualization style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"âœ… Environment ready! Let's learn XGBoost!\")"
      ],
      "id": "bb47d816",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Foundations\n",
        "\n",
        "## Lesson 1: What is Machine Learning Boosting? ðŸ¤”\n",
        "\n",
        "Imagine you're trying to become an expert at predicting weather. Instead of relying on one meteorologist, wouldn't it be better to:\n",
        "1. Ask multiple meteorologists\n",
        "2. Have each one learn from the mistakes of the previous ones\n",
        "3. Combine all their predictions\n",
        "\n",
        "That's **boosting** in a nutshell!\n",
        "\n",
        "### Key Concept:\n",
        "**Boosting** = Combining many \"weak\" learners to create one \"strong\" learner\n"
      ],
      "id": "fd8e63f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's visualize this concept with a simple example\n",
        "# Create a non-linear dataset that's hard for a single model\n",
        "\n",
        "# Generate data\n",
        "np.random.seed(42)\n",
        "X_demo = np.linspace(-3, 3, 300).reshape(-1, 1)\n",
        "y_demo = np.sin(2 * X_demo).ravel() + np.sin(4 * X_demo).ravel() + np.random.normal(0, 0.3, X_demo.shape[0])\n",
        "\n",
        "# Visualize the challenge\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_demo, y_demo, alpha=0.5, s=20)\n",
        "plt.title(\"Our Challenge: Predict this Complex Pattern\", fontsize=14)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "48a69029",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ§  Think About It:\n",
        "Could a single straight line predict this pattern well? How about a simple curve? This is why we need boosting!\n",
        "\n",
        "## Lesson 2: Understanding Decision Trees ðŸŒ³\n",
        "\n",
        "Before we dive into boosting, let's understand the building block: **Decision Trees**.\n",
        "\n",
        "A decision tree makes predictions by asking a series of yes/no questions:\n",
        "- Is X > 5? â†’ Yes â†’ Is Y < 3? â†’ Yes â†’ Predict Class A\n",
        "\n",
        "Let's see this in action:\n"
      ],
      "id": "761cf276"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a simple classification dataset\n",
        "X_tree, y_tree = make_classification(n_samples=100, n_features=2, n_redundant=0, \n",
        "                                     n_informative=2, n_clusters_per_class=1, \n",
        "                                     random_state=42, flip_y=0.1)\n",
        "\n",
        "# Visualize the data\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "scatter = plt.scatter(X_tree[:, 0], X_tree[:, 1], c=y_tree, cmap='viridis', s=50, edgecolor='k')\n",
        "plt.title(\"Our Classification Problem\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.colorbar(scatter, label='Class')\n",
        "\n",
        "# Train a simple decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree_model.fit(X_tree, y_tree)\n",
        "\n",
        "# Visualize decision boundaries\n",
        "plt.subplot(1, 2, 2)\n",
        "x_min, x_max = X_tree[:, 0].min() - 1, X_tree[:, 0].max() + 1\n",
        "y_min, y_max = X_tree[:, 1].min() - 1, X_tree[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
        "Z = tree_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
        "plt.scatter(X_tree[:, 0], X_tree[:, 1], c=y_tree, cmap='viridis', s=50, edgecolor='k')\n",
        "plt.title(\"Decision Tree Boundaries\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "e8f6adf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Exercise 1: Tree Depth Impact\n",
        "\n",
        "**Task**: Modify the tree depth and observe how it affects the decision boundaries. What happens with depth=1 vs depth=10?\n"
      ],
      "id": "21e680df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exercise 1: Try different tree depths\n",
        "depths_to_try = [1, 3, 10]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for idx, depth in enumerate(depths_to_try):\n",
        "    # TODO: Train a tree with the specified depth\n",
        "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    tree.fit(X_tree, y_tree)\n",
        "    \n",
        "    # Visualization code (uncomment when you've trained the tree)\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
        "    Z = tree.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    axes[idx].contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
        "    axes[idx].scatter(X_tree[:, 0], X_tree[:, 1], c=y_tree, cmap='viridis', s=50, edgecolor='k')\n",
        "    axes[idx].set_title(f'Depth = {depth}')\n",
        "    \n",
        "    # Placeholder\n",
        "    # axes[idx].text(0.5, 0.5, f'TODO: Depth={depth}', ha='center', va='center', transform=axes[idx].transAxes)\n",
        "    # axes[idx].set_title(f'Depth = {depth}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸ’­ What do you notice? Shallow trees are simple (underfitting), deep trees are complex (overfitting)!\")"
      ],
      "id": "5dbdf0fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 3: From Single Trees to Ensemble Methods ðŸŒ²ðŸŒ²ðŸŒ²\n",
        "\n",
        "A single tree can be:\n",
        "- **Too simple** (underfitting): Misses important patterns\n",
        "- **Too complex** (overfitting): Memorizes noise\n",
        "\n",
        "**Solution**: Use multiple trees and combine their predictions!\n",
        "\n",
        "There are two main approaches:\n",
        "1. **Bagging** (Random Forest): Trees learn independently in parallel\n",
        "2. **Boosting** (XGBoost): Trees learn sequentially, each fixing the errors of the previous\n"
      ],
      "id": "d9b41219"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's demonstrate the difference between a single tree and boosting\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Use our sine wave data from earlier - but do a proper random split\n",
        "# so models interpolate rather than extrapolate\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_demo, y_demo, test_size=0.33, random_state=42\n",
        ")\n",
        "\n",
        "# Train different models\n",
        "single_tree = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "single_tree.fit(X_train, y_train)\n",
        "\n",
        "boosted_trees = GradientBoostingRegressor(n_estimators=50, max_depth=3, random_state=42)\n",
        "boosted_trees.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "pred_single = single_tree.predict(X_test)\n",
        "pred_boosted = boosted_trees.predict(X_test)\n",
        "\n",
        "# For better visualization, let's sort the test data by X values\n",
        "sort_idx = np.argsort(X_test.ravel())\n",
        "X_test_sorted = X_test[sort_idx]\n",
        "y_test_sorted = y_test[sort_idx]\n",
        "pred_single_sorted = pred_single[sort_idx]\n",
        "pred_boosted_sorted = pred_boosted[sort_idx]\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Single tree\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X_train, y_train, alpha=0.5, s=20, label='Training data', color='lightblue')\n",
        "plt.plot(X_test_sorted, pred_single_sorted, 'r-', linewidth=2, label='Single tree prediction')\n",
        "plt.scatter(X_test, y_test, alpha=0.7, s=15, label='Test data', color='pink')\n",
        "plt.title('Single Decision Tree')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Boosted trees\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X_train, y_train, alpha=0.5, s=20, label='Training data', color='lightblue')\n",
        "plt.plot(X_test_sorted, pred_boosted_sorted, 'g-', linewidth=2, label='Boosted trees prediction')\n",
        "plt.scatter(X_test, y_test, alpha=0.7, s=15, label='Test data', color='pink')\n",
        "plt.title('Gradient Boosting (50 trees)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Comparison\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(X_test_sorted, y_test_sorted, 'k-', linewidth=2, label='True function', alpha=0.7)\n",
        "plt.plot(X_test_sorted, pred_single_sorted, 'r--', linewidth=2, label='Single tree', alpha=0.7)\n",
        "plt.plot(X_test_sorted, pred_boosted_sorted, 'g--', linewidth=2, label='Boosted trees', alpha=0.7)\n",
        "plt.title('Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate errors\n",
        "mse_single = mean_squared_error(y_test, pred_single)\n",
        "mse_boosted = mean_squared_error(y_test, pred_boosted)\n",
        "print(f\"ðŸ“Š Single Tree MSE: {mse_single:.4f}\")\n",
        "print(f\"ðŸ“Š Boosted Trees MSE: {mse_boosted:.4f}\")\n",
        "print(f\"ðŸŽ¯ Improvement: {(1 - mse_boosted/mse_single)*100:.1f}%\")"
      ],
      "id": "d77f8927",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's visualize the structure of our single decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(single_tree, \n",
        "          filled=True, \n",
        "          feature_names=['X'], \n",
        "          rounded=True, \n",
        "          fontsize=8,\n",
        "          proportion=False,\n",
        "          impurity=True,\n",
        "          class_names=None)\n",
        "plt.title('Decision Tree Structure (max_depth=3)\\nShows how the tree partitions the input space', fontsize=16, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸŒ³ Understanding the Tree:\")\n",
        "print(\"- Each box is a node showing the decision rule\")\n",
        "print(\"- Colors represent different prediction values\")\n",
        "print(\"- The tree creates step-like boundaries in the prediction\")\n",
        "print(\"- This is why a single tree has limited flexibility for complex patterns!\")"
      ],
      "id": "7166baa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ” Understanding the Decision Tree Values\n",
        "\n",
        "Each node (box) in the tree contains important information:\n",
        "\n",
        "**ðŸŽ¯ Decision Rule**: `X <= 2.207`\n",
        "- This is the question the tree asks at each split\n",
        "- Data points go **left (True)** if X â‰¤ 2.207, **right (False)** if X > 2.207\n",
        "\n",
        "**ðŸ“Š Squared Error**: `squared_error = 1.11`\n",
        "- Measures how \"pure\" or homogeneous this node is\n",
        "- Lower values = more consistent predictions in this region\n",
        "- The tree tries to minimize this when choosing splits\n",
        "\n",
        "**ðŸ‘¥ Samples**: `samples = 201`\n",
        "- Number of training data points that reach this node\n",
        "- Root node has all 201 training samples\n",
        "- Leaf nodes have fewer samples after successive splits\n",
        "\n",
        "**ðŸŽ¯ Value**: `value = -0.067`\n",
        "- The **prediction** for data points that end up in this node\n",
        "- For regression: this is the average target value of samples in this node\n",
        "- This is what the tree predicts for new data points reaching this node\n",
        "\n",
        "**ðŸŽ¨ Colors**:\n",
        "- **Darker orange**: Higher (more positive) predictions\n",
        "- **Lighter colors**: Lower (more negative) predictions\n",
        "- **White/Light**: Predictions close to zero\n",
        "\n",
        "### ðŸ”„ How Predictions Work:\n",
        "1. Start at the **root node** (top)\n",
        "2. Follow the **decision rules** down the tree\n",
        "3. End at a **leaf node** (bottom row)\n",
        "4. Use that leaf's **value** as your prediction!\n",
        "\n",
        "## Lesson 4: How Gradient Boosting Works ðŸ”§\n",
        "\n",
        "Let's break down the magic of gradient boosting step by step:\n",
        "\n",
        "### The Algorithm:\n",
        "1. **Start** with a simple prediction (like the mean)\n",
        "2. **Calculate** the errors (residuals)\n",
        "3. **Train** a new tree to predict these errors\n",
        "4. **Add** this tree's predictions (scaled down) to improve our model\n",
        "5. **Repeat** steps 2-4\n",
        "\n",
        "Think of it like improving your aim in darts:\n",
        "- First throw: You miss by a lot\n",
        "- Second throw: You adjust based on how much you missed\n",
        "- Third throw: You make smaller adjustments\n",
        "- Eventually: You hit the bullseye!\n"
      ],
      "id": "d764aec8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's build gradient boosting from scratch to understand it!\n",
        "class SimpleGradientBoosting:\n",
        "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "        self.init_prediction = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Step 1: Initial prediction (mean)\n",
        "        self.init_prediction = np.mean(y)\n",
        "        predictions = np.full(len(y), self.init_prediction)\n",
        "        \n",
        "        # Store predictions at each iteration for visualization\n",
        "        self.iteration_predictions = [predictions.copy()]\n",
        "        \n",
        "        for i in range(self.n_estimators):\n",
        "            # Step 2: Calculate residuals\n",
        "            residuals = y - predictions\n",
        "            \n",
        "            # Step 3: Train tree on residuals\n",
        "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=42+i)\n",
        "            tree.fit(X, residuals)\n",
        "            \n",
        "            # Step 4: Update predictions\n",
        "            predictions += self.learning_rate * tree.predict(X)\n",
        "            \n",
        "            self.trees.append(tree)\n",
        "            self.iteration_predictions.append(predictions.copy())\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predictions = np.full(len(X), self.init_prediction)\n",
        "        for tree in self.trees:\n",
        "            predictions += self.learning_rate * tree.predict(X)\n",
        "        return predictions\n",
        "\n",
        "# Train our simple gradient boosting\n",
        "X_simple = X_demo[:200].reshape(-1, 1)\n",
        "y_simple = y_demo[:200]\n",
        "\n",
        "gb_model = SimpleGradientBoosting(n_estimators=5, learning_rate=0.3, max_depth=3)\n",
        "gb_model.fit(X_simple, y_simple)\n",
        "\n",
        "# Visualize the boosting process\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(6):\n",
        "    ax = axes[i]\n",
        "    ax.scatter(X_simple, y_simple, alpha=0.5, s=20, label='True data')\n",
        "    \n",
        "    if i == 0:\n",
        "        ax.axhline(y=gb_model.init_prediction, color='r', linestyle='--', \n",
        "                   label=f'Initial prediction (mean={gb_model.init_prediction:.2f})')\n",
        "        ax.set_title('Step 0: Initial Prediction')\n",
        "    else:\n",
        "        # Sort for smooth line plot\n",
        "        sort_idx = np.argsort(X_simple.ravel())\n",
        "        ax.plot(X_simple[sort_idx], gb_model.iteration_predictions[i-1][sort_idx], \n",
        "                'r-', linewidth=2, label=f'After {i} trees')\n",
        "        ax.set_title(f'After {i} Tree(s)')\n",
        "    \n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_ylim(-3, 3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸŽ¯ See how each tree improves the prediction? That's the power of boosting!\")"
      ],
      "id": "6fc32c21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Exercise 2: Learning Rate Experiment\n",
        "\n",
        "The learning rate controls how much we trust each new tree. Let's experiment!\n"
      ],
      "id": "11930896"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exercise 2: Impact of learning rate\n",
        "learning_rates = [0.01, 0.1, 0.5, 1.0]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for idx, lr in enumerate(learning_rates):\n",
        "    plt.subplot(2, 2, idx + 1)\n",
        "    \n",
        "    # TODO: Train a gradient boosting model with the specified learning rate\n",
        "    model = SimpleGradientBoosting(n_estimators=20, learning_rate=lr, max_depth=3)\n",
        "    model.fit(X_simple, y_simple)\n",
        "    predictions = model.predict(X_simple)\n",
        "    \n",
        "    # TODO: Plot the results\n",
        "    plt.scatter(X_simple, y_simple, alpha=0.5, s=20)\n",
        "    sort_idx = np.argsort(X_simple.ravel())\n",
        "    plt.plot(X_simple[sort_idx], predictions[sort_idx], 'r-', linewidth=2)\n",
        "    plt.title(f'Learning Rate = {lr}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Placeholder\n",
        "    # plt.text(0.5, 0.5, f'TODO: LR={lr}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    # plt.title(f'Learning Rate = {lr}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸ’­ Question: Which learning rate gives the smoothest predictions? Why?\")"
      ],
      "id": "73f040dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 5: Enter XGBoost! ðŸš€\n",
        "\n",
        "XGBoost (eXtreme Gradient Boosting) is gradient boosting on steroids! It adds:\n",
        "\n",
        "### 1. **Speed Improvements**:\n",
        "- Parallel processing\n",
        "- Cache optimization\n",
        "- Efficient data structures\n",
        "\n",
        "### 2. **Accuracy Improvements**:\n",
        "- Regularization (L1 & L2)\n",
        "- Better handling of missing values\n",
        "- More intelligent tree pruning\n",
        "\n",
        "### 3. **Flexibility**:\n",
        "- Custom objective functions\n",
        "- Built-in cross-validation\n",
        "- Early stopping\n",
        "\n",
        "Let's see XGBoost in action!\n"
      ],
      "id": "e74ab1e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compare regular gradient boosting with XGBoost\n",
        "from time import time\n",
        "\n",
        "# Create a larger dataset to see speed differences\n",
        "X_large, y_large = make_classification(n_samples=5000, n_features=20, \n",
        "                                       n_informative=15, random_state=42)\n",
        "X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
        "    X_large, y_large, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Regular Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "start_time = time()\n",
        "gb_sklearn = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_sklearn.fit(X_train_large, y_train_large)\n",
        "gb_time = time() - start_time\n",
        "gb_score = gb_sklearn.score(X_test_large, y_test_large)\n",
        "\n",
        "# XGBoost\n",
        "start_time = time()\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "xgb_model.fit(X_train_large, y_train_large)\n",
        "xgb_time = time() - start_time\n",
        "xgb_score = xgb_model.score(X_test_large, y_test_large)\n",
        "\n",
        "# Results\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Gradient Boosting', 'XGBoost'],\n",
        "    'Training Time (s)': [gb_time, xgb_time],\n",
        "    'Accuracy': [gb_score, xgb_score]\n",
        "})\n",
        "\n",
        "# Visualize comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Training time\n",
        "ax1.bar(results_df['Model'], results_df['Training Time (s)'], color=['blue', 'red'])\n",
        "ax1.set_ylabel('Training Time (seconds)')\n",
        "ax1.set_title('Training Speed Comparison')\n",
        "\n",
        "# Accuracy\n",
        "ax2.bar(results_df['Model'], results_df['Accuracy'], color=['blue', 'red'])\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Model Performance')\n",
        "ax2.set_ylim(0.9, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(results_df)\n",
        "print(f\"\\nâš¡ XGBoost is {gb_time/xgb_time:.1f}x faster!\")"
      ],
      "id": "97b38e23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 6: XGBoost Parameters Deep Dive ðŸŽ›ï¸\n",
        "\n",
        "XGBoost has many parameters, but let's focus on the most important ones:\n",
        "\n",
        "### ðŸŒ³ Tree Parameters:\n",
        "- `max_depth`: How deep can trees grow? (default: 6)\n",
        "- `min_child_weight`: Minimum data in leaf nodes (default: 1)\n",
        "- `gamma`: Minimum loss reduction for split (default: 0)\n",
        "\n",
        "### ðŸ“š Boosting Parameters:\n",
        "- `n_estimators`: Number of trees (default: 100)\n",
        "- `learning_rate`: Step size (default: 0.3)\n",
        "- `subsample`: Fraction of data per tree (default: 1.0)\n",
        "\n",
        "### ðŸ›¡ï¸ Regularization Parameters:\n",
        "- `reg_alpha`: L1 regularization (default: 0)\n",
        "- `reg_lambda`: L2 regularization (default: 1)\n",
        "- `colsample_bytree`: Fraction of features per tree (default: 1.0)\n"
      ],
      "id": "c269845f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Interactive parameter exploration\n",
        "# Let's see how max_depth and n_estimators affect performance\n",
        "\n",
        "# Create a dataset\n",
        "X_param, y_param = make_classification(n_samples=1000, n_features=10, \n",
        "                                       n_informative=8, random_state=42)\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
        "    X_param, y_param, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Parameter grid\n",
        "max_depths = [2, 4, 6, 8, 10]\n",
        "n_estimators_list = [10, 50, 100, 200]\n",
        "\n",
        "# Store results\n",
        "results = np.zeros((len(max_depths), len(n_estimators_list)))\n",
        "\n",
        "for i, max_depth in enumerate(max_depths):\n",
        "    for j, n_est in enumerate(n_estimators_list):\n",
        "        model = xgb.XGBClassifier(\n",
        "            max_depth=max_depth,\n",
        "            n_estimators=n_est,\n",
        "            random_state=42,\n",
        "            eval_metric='logloss'\n",
        "        )\n",
        "        model.fit(X_train_p, y_train_p, verbose=False)\n",
        "        results[i, j] = model.score(X_test_p, y_test_p)\n",
        "\n",
        "# Heatmap visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(results, annot=True, fmt='.3f', \n",
        "            xticklabels=n_estimators_list,\n",
        "            yticklabels=max_depths,\n",
        "            cmap='YlOrRd')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.ylabel('Max Depth')\n",
        "plt.title('XGBoost Performance: Impact of Key Parameters')\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸŽ¯ Notice: More trees and deeper trees generally improve performance, but with diminishing returns!\")"
      ],
      "id": "91f51843",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Exercise 3: Regularization Experiment\n",
        "\n",
        "Regularization helps prevent overfitting. Let's see it in action!\n"
      ],
      "id": "2afe5af1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exercise 3: Effect of regularization\n",
        "# Create an overfitting scenario with few samples and many features\n",
        "X_overfit, y_overfit = make_classification(n_samples=200, n_features=50, \n",
        "                                           n_informative=10, random_state=42)\n",
        "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(\n",
        "    X_overfit, y_overfit, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# TODO: Train two models - one without regularization, one with\n",
        "model_no_reg = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=0,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "model_with_reg = xgb.XGBClassifier(\n",
        "    n_estimators=300,         # More trees, but each learns less (due to low learning rate)\n",
        "    max_depth=6,              # Shallower trees to reduce complexity\n",
        "    learning_rate=0.05,       # Slower learning, helps regularization\n",
        "    reg_alpha=10,             # Strong L1 regularization (feature selection)\n",
        "    reg_lambda=10,            # Strong L2 regularization (weight shrinkage)\n",
        "    subsample=0.7,            # Use 70% of data per tree (adds randomness)\n",
        "    colsample_bytree=0.7,     # Use 70% of features per tree (adds randomness)\n",
        "    min_child_weight=5,       # Require more samples per leaf (prevents small, specific splits)\n",
        "    gamma=1,                  # Minimum loss reduction for split (prevents unnecessary splits)\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "# Fit both models\n",
        "print(\"ðŸš€ Training models...\")\n",
        "model_no_reg.fit(X_train_o, y_train_o)\n",
        "\n",
        "# Train regularized model\n",
        "print(\"ðŸ›¡ï¸ Training strongly regularized model...\")\n",
        "model_with_reg.fit(X_train_o, y_train_o)\n",
        "\n",
        "# Calculate accuracies\n",
        "train_acc_no_reg = model_no_reg.score(X_train_o, y_train_o)\n",
        "test_acc_no_reg = model_no_reg.score(X_test_o, y_test_o)\n",
        "\n",
        "train_acc_with_reg = model_with_reg.score(X_train_o, y_train_o)\n",
        "test_acc_with_reg = model_with_reg.score(X_test_o, y_test_o)\n",
        "\n",
        "# Create comparison visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Bar plot comparing accuracies\n",
        "models = ['No Regularization', 'With Regularization']\n",
        "train_scores = [train_acc_no_reg, train_acc_with_reg]\n",
        "test_scores = [test_acc_no_reg, test_acc_with_reg]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax1.bar(x - width/2, train_scores, width, label='Training Accuracy', color='skyblue', alpha=0.8)\n",
        "bars2 = ax1.bar(x + width/2, test_scores, width, label='Test Accuracy', color='lightcoral', alpha=0.8)\n",
        "\n",
        "ax1.set_xlabel('Model Type')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Training vs Test Accuracy: Overfitting Demo')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "             f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "             f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Overfitting gap visualization\n",
        "overfitting_gap_no_reg = train_acc_no_reg - test_acc_no_reg\n",
        "overfitting_gap_with_reg = train_acc_with_reg - test_acc_with_reg\n",
        "\n",
        "gaps = [overfitting_gap_no_reg, overfitting_gap_with_reg]\n",
        "colors = ['red' if gap > 0.05 else 'green' for gap in gaps]\n",
        "\n",
        "bars3 = ax2.bar(models, gaps, color=colors, alpha=0.7)\n",
        "ax2.set_ylabel('Overfitting Gap (Train - Test)')\n",
        "ax2.set_title('Overfitting Gap Comparison')\n",
        "ax2.axhline(y=0.05, color='orange', linestyle='--', label='Concerning Threshold (5%)')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, gap) in enumerate(zip(bars3, gaps)):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.002,\n",
        "             f'{gap:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed results\n",
        "print(\"ðŸ“Š Regularization Impact Results:\")\n",
        "print(\"=\"*50)\n",
        "print(\"WITHOUT REGULARIZATION:\")\n",
        "print(f\"  Max Depth: 10 (very deep)\")\n",
        "print(f\"  Regularization: None (reg_alpha=0, reg_lambda=0)\")\n",
        "print(f\"  Trees Used: 100\")\n",
        "print(f\"  Training Accuracy: {train_acc_no_reg:.3f}\")\n",
        "print(f\"  Test Accuracy:     {test_acc_no_reg:.3f}\")\n",
        "print(f\"  Overfitting Gap:   {overfitting_gap_no_reg:.3f}\")\n",
        "print(f\"  Status: {'ðŸ”´ OVERFITTING' if overfitting_gap_no_reg > 0.05 else 'ðŸŸ¢ OK'}\")\n",
        "\n",
        "print(\"\\nWITH STRONG REGULARIZATION:\")\n",
        "print(f\"  Max Depth: 6 (moderate)\")\n",
        "print(f\"  L1/L2 Regularization: 10/10 (strong)\")\n",
        "print(f\"  Subsampling: 70% data, 70% features\")\n",
        "print(f\"  Trees Used: 50 (reduced to prevent overfitting)\")\n",
        "print(f\"  Training Accuracy: {train_acc_with_reg:.3f}\")\n",
        "print(f\"  Test Accuracy:     {test_acc_with_reg:.3f}\")\n",
        "print(f\"  Overfitting Gap:   {overfitting_gap_with_reg:.3f}\")\n",
        "print(f\"  Status: {'ðŸ”´ OVERFITTING' if overfitting_gap_with_reg > 0.05 else 'ðŸŸ¢ OK'}\")\n",
        "\n",
        "gap_reduction = overfitting_gap_no_reg - overfitting_gap_with_reg\n",
        "print(f\"\\nðŸ’¡ IMPROVEMENTS:\")\n",
        "print(f\"  Overfitting reduction: {gap_reduction:.3f}\")\n",
        "print(f\"  Test accuracy improvement: {test_acc_with_reg - test_acc_no_reg:.3f}\")\n",
        "print(f\"  Percentage overfitting reduction: {(gap_reduction/overfitting_gap_no_reg)*100:.1f}%\")\n",
        "\n",
        "if overfitting_gap_with_reg <= 0.05:\n",
        "    print(\"âœ… SUCCESS: Strong regularization prevented overfitting!\")\n",
        "else:\n",
        "    print(\"âš ï¸  Still some overfitting, but significantly reduced!\")\n",
        "    print(\"ðŸ’¡ For even better results, try:\")\n",
        "    print(\"   - Even shallower trees (max_depth=2)\")\n",
        "    print(\"   - More aggressive early stopping\")\n",
        "    print(\"   - Higher regularization values\")"
      ],
      "id": "3f321f97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 7: Preventing Overfitting in XGBoost ðŸ›¡ï¸\n",
        "\n",
        "XGBoost provides several techniques to prevent overfitting:\n",
        "\n",
        "1. **Early Stopping**: Stop training when validation score stops improving\n",
        "   - *Note: Implementation varies by XGBoost version (parameter vs callback approach)*\n",
        "2. **Cross-Validation**: Built-in CV for parameter tuning\n",
        "3. **Regularization**: L1/L2 penalties\n",
        "4. **Subsampling**: Use random subsets of data/features\n",
        "\n",
        "**Version Compatibility Note**: Early stopping syntax has changed across XGBoost versions.\n",
        "This tutorial demonstrates the concept without version-specific implementation details.\n"
      ],
      "id": "99e9999d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrate the concept of early stopping (without version-specific implementation)\n",
        "# Note: Early stopping implementation varies across XGBoost versions\n",
        "X_early, y_early = make_classification(n_samples=2000, n_features=20, \n",
        "                                       n_informative=15, random_state=42)\n",
        "X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(\n",
        "    X_early, y_early, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train a model with fewer iterations to simulate early stopping concept\n",
        "model_early = xgb.XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=42, eval_metric='logloss')\n",
        "\n",
        "# For demonstration, we'll train multiple models with different numbers of estimators\n",
        "# to show how performance changes (simulating the early stopping decision process)\n",
        "n_estimators_list = [10, 25, 50, 100, 150, 200]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for n_est in n_estimators_list:\n",
        "    temp_model = xgb.XGBClassifier(n_estimators=n_est, learning_rate=0.1, random_state=42, eval_metric='logloss')\n",
        "    temp_model.fit(X_train_e, y_train_e)\n",
        "    \n",
        "    train_score = temp_model.score(X_train_e, y_train_e)\n",
        "    test_score = temp_model.score(X_test_e, y_test_e)\n",
        "    \n",
        "    train_scores.append(train_score)\n",
        "    test_scores.append(test_score)\n",
        "\n",
        "# Plot the learning curves to demonstrate early stopping concept\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_estimators_list, train_scores, 'b-', label='Training Accuracy', marker='o')\n",
        "plt.plot(n_estimators_list, test_scores, 'r-', label='Test Accuracy', marker='s')\n",
        "\n",
        "# Find the point where test score starts to plateau or decrease (early stopping point)\n",
        "best_idx = np.argmax(test_scores)\n",
        "best_n_estimators = n_estimators_list[best_idx]\n",
        "plt.axvline(x=best_n_estimators, color='green', linestyle='--', \n",
        "            label=f'Optimal stopping point ({best_n_estimators} trees)')\n",
        "\n",
        "plt.xlabel('Number of Estimators (Trees)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Early Stopping Concept: Finding Optimal Number of Trees')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Train the final model with the optimal number of estimators\n",
        "model_early = xgb.XGBClassifier(n_estimators=best_n_estimators, learning_rate=0.1, random_state=42, eval_metric='logloss')\n",
        "model_early.fit(X_train_e, y_train_e)\n",
        "\n",
        "print(f\"ðŸŽ¯ Concept Demonstration: Optimal number of trees found: {best_n_estimators}\")\n",
        "print(f\"ðŸ“Š Best test accuracy: {test_scores[best_idx]:.4f}\")\n",
        "print(f\"ðŸ’¡ This demonstrates why early stopping is useful - it prevents overfitting!\")\n",
        "print(f\"\\nâš ï¸  Note: In production, use XGBoost's built-in early stopping features\")\n",
        "print(f\"   (implementation varies by XGBoost version - check your version's documentation)\")"
      ],
      "id": "675f250e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Techniques: Cross-Validation, Regularization & Subsampling ðŸŽ¯\n",
        "\n",
        "Let's explore three powerful techniques that make XGBoost robust:\n",
        "\n",
        "### 1. **Cross-Validation**: Reliable performance estimation\n",
        "### 2. **Regularization**: L1/L2 penalties to prevent overfitting  \n",
        "### 3. **Subsampling**: Random sampling for better generalization\n",
        "\n",
        "### Technique 1: Cross-Validation ðŸ“Š\n",
        "\n",
        "Cross-validation gives us a more reliable estimate of model performance by:\n",
        "- Training on multiple data splits\n",
        "- Reducing variance in performance estimates\n",
        "- Helping with hyperparameter selection\n"
      ],
      "id": "523bb7c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cross-validation demonstration\n",
        "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
        "import time\n",
        "\n",
        "# Create a challenging dataset for cross-validation\n",
        "np.random.seed(42)\n",
        "X_cv, y_cv = make_classification(n_samples=3000, n_features=20, \n",
        "                                 n_informative=10, n_redundant=5,\n",
        "                                 n_clusters_per_class=2, flip_y=0.1, \n",
        "                                 random_state=42)\n",
        "\n",
        "print(\"ðŸ”„ Cross-Validation Comparison\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Single train-test split\n",
        "X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(\n",
        "    X_cv, y_cv, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "model_single = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "start_time = time.time()\n",
        "model_single.fit(X_train_single, y_train_single)\n",
        "single_score = model_single.score(X_test_single, y_test_single)\n",
        "single_time = time.time() - start_time\n",
        "\n",
        "print(f\"ðŸ“ˆ Single Split Result:\")\n",
        "print(f\"   Accuracy: {single_score:.4f}\")\n",
        "print(f\"   Time: {single_time:.2f}s\")\n",
        "\n",
        "# Cross-validation with different folds\n",
        "cv_results = {}\n",
        "fold_options = [3, 5, 10]\n",
        "\n",
        "for n_folds in fold_options:\n",
        "    start_time = time.time()\n",
        "    cv_scores = cross_val_score(\n",
        "        xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
        "        X_cv, y_cv, \n",
        "        cv=StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42),\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    cv_time = time.time() - start_time\n",
        "    \n",
        "    cv_results[n_folds] = {\n",
        "        'mean': cv_scores.mean(),\n",
        "        'std': cv_scores.std(),\n",
        "        'scores': cv_scores,\n",
        "        'time': cv_time\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nðŸ“Š {n_folds}-Fold Cross-Validation:\")\n",
        "    print(f\"   Mean Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
        "    print(f\"   Individual Folds: {[f'{score:.3f}' for score in cv_scores]}\")\n",
        "    print(f\"   Time: {cv_time:.2f}s\")\n",
        "\n",
        "# Visualize cross-validation results\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Box plot of CV scores\n",
        "cv_data = [cv_results[k]['scores'] for k in fold_options]\n",
        "bp = ax1.boxplot(cv_data, labels=[f'{k}-Fold' for k in fold_options], patch_artist=True)\n",
        "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "ax1.axhline(y=single_score, color='red', linestyle='--', \n",
        "           label=f'Single Split ({single_score:.3f})')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Cross-Validation Score Distribution')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Mean scores with error bars\n",
        "means = [cv_results[k]['mean'] for k in fold_options]\n",
        "stds = [cv_results[k]['std'] for k in fold_options]\n",
        "ax2.errorbar(fold_options, means, yerr=stds, marker='o', capsize=5, capthick=2)\n",
        "ax2.axhline(y=single_score, color='red', linestyle='--', \n",
        "           label=f'Single Split ({single_score:.3f})')\n",
        "ax2.set_xlabel('Number of Folds')\n",
        "ax2.set_ylabel('Mean Accuracy')\n",
        "ax2.set_title('Cross-Validation: Mean Â± Std')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nðŸ’¡ Key Insights:\")\n",
        "print(f\"   â€¢ Cross-validation provides confidence intervals\")\n",
        "print(f\"   â€¢ More folds = more reliable estimates (but slower)\")\n",
        "print(f\"   â€¢ Single split can be misleading due to lucky/unlucky splits\")"
      ],
      "id": "132aab03",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Technique 2: Regularization Deep Dive ðŸ›¡ï¸\n",
        "\n",
        "Regularization adds penalties to prevent overfitting:\n",
        "- **L1 (Lasso)**: Encourages sparsity, automatic feature selection\n",
        "- **L2 (Ridge)**: Shrinks weights, handles multicollinearity\n",
        "- **Elastic Net**: Combines L1 + L2\n"
      ],
      "id": "c6ddc45f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comprehensive regularization demonstration\n",
        "# Create a dataset prone to overfitting (many features, few samples)\n",
        "np.random.seed(42)\n",
        "X_reg, y_reg = make_classification(n_samples=500, n_features=100, \n",
        "                                   n_informative=20, n_redundant=20,\n",
        "                                   random_state=42)\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(\"ðŸ›¡ï¸ Regularization Impact Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Test different regularization configurations\n",
        "reg_configs = [\n",
        "    {'name': 'No Regularization', 'reg_alpha': 0, 'reg_lambda': 0},\n",
        "    {'name': 'L1 Only (Lasso)', 'reg_alpha': 10, 'reg_lambda': 0},\n",
        "    {'name': 'L2 Only (Ridge)', 'reg_alpha': 0, 'reg_lambda': 10},\n",
        "    {'name': 'L1 + L2 (Elastic)', 'reg_alpha': 5, 'reg_lambda': 5},\n",
        "    {'name': 'Strong L1', 'reg_alpha': 50, 'reg_lambda': 0},\n",
        "    {'name': 'Strong L2', 'reg_alpha': 0, 'reg_lambda': 50}\n",
        "]\n",
        "\n",
        "reg_results = []\n",
        "\n",
        "for config in reg_configs:\n",
        "    # Train model with specific regularization\n",
        "    model = xgb.XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=8,  # Deep trees to encourage overfitting\n",
        "        learning_rate=0.1,\n",
        "        reg_alpha=config['reg_alpha'],\n",
        "        reg_lambda=config['reg_lambda'],\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    \n",
        "    model.fit(X_train_reg, y_train_reg)\n",
        "    \n",
        "    train_acc = model.score(X_train_reg, y_train_reg)\n",
        "    test_acc = model.score(X_test_reg, y_test_reg)\n",
        "    overfitting_gap = train_acc - test_acc\n",
        "    \n",
        "    # Count non-zero feature importances (sparsity measure)\n",
        "    non_zero_features = np.sum(model.feature_importances_ > 1e-6)\n",
        "    \n",
        "    reg_results.append({\n",
        "        'config': config['name'],\n",
        "        'train_acc': train_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'gap': overfitting_gap,\n",
        "        'features_used': non_zero_features,\n",
        "        'reg_alpha': config['reg_alpha'],\n",
        "        'reg_lambda': config['reg_lambda']\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for easy analysis\n",
        "reg_df = pd.DataFrame(reg_results)\n",
        "print(reg_df[['config', 'train_acc', 'test_acc', 'gap', 'features_used']].round(4))\n",
        "\n",
        "# Visualize regularization effects\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Training vs Test Accuracy\n",
        "x_pos = np.arange(len(reg_configs))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax1.bar(x_pos - width/2, reg_df['train_acc'], width, \n",
        "                label='Training Accuracy', alpha=0.8, color='skyblue')\n",
        "bars2 = ax1.bar(x_pos + width/2, reg_df['test_acc'], width, \n",
        "                label='Test Accuracy', alpha=0.8, color='lightcoral')\n",
        "ax1.set_xlabel('Regularization Type')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Training vs Test Accuracy by Regularization')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels(reg_df['config'], rotation=45, ha='right')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (mean, std) in enumerate(zip(reg_df['train_acc'], reg_df['reg_lambda'])):\n",
        "    ax1.text(i, mean + std + 0.005, f'{mean:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 2. Overfitting Gap\n",
        "colors = ['red' if gap > 0.05 else 'orange' if gap > 0.02 else 'green' \n",
        "          for gap in reg_df['gap']]\n",
        "bars3 = ax2.bar(reg_df['config'], reg_df['gap'], color=colors, alpha=0.7)\n",
        "ax2.set_ylabel('Overfitting Gap')\n",
        "ax2.set_title('Overfitting Gap by Regularization')\n",
        "ax2.set_xticklabels(reg_df['config'], rotation=45, ha='right')\n",
        "ax2.axhline(y=0.05, color='red', linestyle='--', alpha=0.5, label='High Risk')\n",
        "ax2.axhline(y=0.02, color='orange', linestyle='--', alpha=0.5, label='Moderate Risk')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Add gap values\n",
        "for bar, gap in zip(bars3, reg_df['gap']):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.002,\n",
        "             f'{gap:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 3. Feature Sparsity (L1 effect)\n",
        "ax3.bar(reg_df['config'], reg_df['features_used'], color='purple', alpha=0.6)\n",
        "ax3.set_ylabel('Number of Features Used')\n",
        "ax3.set_title('Feature Sparsity: L1 Regularization Effect')\n",
        "ax3.set_xticklabels(reg_df['config'], rotation=45, ha='right')\n",
        "ax3.axhline(y=100, color='gray', linestyle='--', alpha=0.5, label='Total Features')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Regularization Strength vs Performance\n",
        "l1_strengths = reg_df['reg_alpha'].values\n",
        "l2_strengths = reg_df['reg_lambda'].values\n",
        "test_accs = reg_df['test_acc'].values\n",
        "\n",
        "# Create scatter plot\n",
        "scatter = ax4.scatter(l1_strengths, l2_strengths, c=test_accs, s=200, \n",
        "                     cmap='viridis', alpha=0.8, edgecolors='black')\n",
        "ax4.set_xlabel('L1 Regularization (reg_alpha)')\n",
        "ax4.set_ylabel('L2 Regularization (reg_lambda)')\n",
        "ax4.set_title('Regularization Strength vs Test Performance')\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(scatter, ax=ax4)\n",
        "cbar.set_label('Test Accuracy')\n",
        "\n",
        "# Annotate points\n",
        "for i, config in enumerate(reg_df['config']):\n",
        "    ax4.annotate(f'{i+1}', (l1_strengths[i], l2_strengths[i]), \n",
        "                xytext=(5, 5), textcoords='offset points', \n",
        "                fontsize=10, fontweight='bold', color='white')\n",
        "\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed analysis\n",
        "print(f\"\\nðŸ“Š Regularization Analysis:\")\n",
        "print(\"=\"*50)\n",
        "best_config = reg_df.loc[reg_df['test_acc'].idxmax()]\n",
        "lowest_gap = reg_df.loc[reg_df['gap'].idxmin()]\n",
        "\n",
        "print(f\"ðŸ† Best Test Performance: {best_config['config']}\")\n",
        "print(f\"   Test Accuracy: {best_config['test_acc']:.4f}\")\n",
        "print(f\"   Overfitting Gap: {best_config['gap']:.4f}\")\n",
        "print(f\"   Features Used: {best_config['features_used']}/100\")\n",
        "\n",
        "print(f\"\\nðŸ›¡ï¸ Lowest Overfitting: {lowest_gap['config']}\")\n",
        "print(f\"   Test Accuracy: {lowest_gap['test_acc']:.4f}\")\n",
        "print(f\"   Overfitting Gap: {lowest_gap['gap']:.4f}\")\n",
        "print(f\"   Features Used: {lowest_gap['features_used']}/100\")\n",
        "\n",
        "print(f\"\\nðŸ’¡ Key Observations:\")\n",
        "print(f\"   â€¢ L1 regularization reduces feature usage (sparsity)\")\n",
        "print(f\"   â€¢ L2 regularization smooths weights (generalization)\")\n",
        "print(f\"   â€¢ Strong regularization may hurt performance\")\n",
        "print(f\"   â€¢ Combination (Elastic Net) often works best\")"
      ],
      "id": "9490c753",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Technique 3: Subsampling Strategies ðŸŽ²\n",
        "\n",
        "Subsampling adds randomness to improve generalization:\n",
        "- **Row Subsampling (subsample)**: Use random subset of training data\n",
        "- **Column Subsampling (colsample_bytree)**: Use random subset of features\n",
        "- **Column Subsampling by Level (colsample_bylevel)**: Different features per tree level\n"
      ],
      "id": "3f39461c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comprehensive subsampling demonstration\n",
        "print(\"ðŸŽ² Subsampling Techniques Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create a moderately complex dataset\n",
        "np.random.seed(42)\n",
        "X_sub, y_sub = make_classification(n_samples=2000, n_features=50, \n",
        "                                   n_informative=25, n_redundant=10,\n",
        "                                   random_state=42)\n",
        "\n",
        "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
        "    X_sub, y_sub, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Test different subsampling configurations\n",
        "subsample_configs = [\n",
        "    {'name': 'No Subsampling', 'subsample': 1.0, 'colsample_bytree': 1.0, 'colsample_bylevel': 1.0},\n",
        "    {'name': 'Row Subsampling', 'subsample': 0.8, 'colsample_bytree': 1.0, 'colsample_bylevel': 1.0},\n",
        "    {'name': 'Column Subsampling', 'subsample': 1.0, 'colsample_bytree': 0.8, 'colsample_bylevel': 1.0},\n",
        "    {'name': 'Level Subsampling', 'subsample': 1.0, 'colsample_bytree': 1.0, 'colsample_bylevel': 0.8},\n",
        "    {'name': 'Row + Column', 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 1.0},\n",
        "    {'name': 'All Subsampling', 'subsample': 0.7, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.8},\n",
        "    {'name': 'Aggressive Sub.', 'subsample': 0.6, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.7}\n",
        "]\n",
        "\n",
        "# Train models and evaluate with cross-validation for more robust results\n",
        "subsample_results = []\n",
        "\n",
        "for config in subsample_configs:\n",
        "    print(f\"âš™ï¸ Testing {config['name']}...\")\n",
        "    \n",
        "    model = xgb.XGBClassifier(\n",
        "        n_estimators=150,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        subsample=config['subsample'],\n",
        "        colsample_bytree=config['colsample_bytree'],\n",
        "        colsample_bylevel=config['colsample_bylevel'],\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    \n",
        "    # Use 3-fold CV for faster evaluation\n",
        "    cv_scores = cross_val_score(model, X_train_sub, y_train_sub, \n",
        "                               cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    \n",
        "    # Also train on full training set for train/test comparison\n",
        "    model.fit(X_train_sub, y_train_sub)\n",
        "    train_acc = model.score(X_train_sub, y_train_sub)\n",
        "    test_acc = model.score(X_test_sub, y_test_sub)\n",
        "    \n",
        "    subsample_results.append({\n",
        "        'config': config['name'],\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'train_acc': train_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'gap': train_acc - test_acc,\n",
        "        'subsample': config['subsample'],\n",
        "        'colsample_bytree': config['colsample_bytree'],\n",
        "        'colsample_bylevel': config['colsample_bylevel'],\n",
        "        'cv_scores': cv_scores\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "sub_df = pd.DataFrame(subsample_results)\n",
        "print(\"\\nðŸ“Š Subsampling Results:\")\n",
        "display_cols = ['config', 'cv_mean', 'cv_std', 'train_acc', 'test_acc', 'gap']\n",
        "print(sub_df[display_cols].round(4))\n",
        "\n",
        "# Comprehensive visualization\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "\n",
        "# 1. CV Scores with error bars\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "cv_means = sub_df['cv_mean']\n",
        "cv_stds = sub_df['cv_std']\n",
        "x_pos = np.arange(len(subsample_configs))\n",
        "\n",
        "bars = ax1.bar(x_pos, cv_means, yerr=cv_stds, capsize=5, \n",
        "               alpha=0.8, color='lightblue', edgecolor='navy')\n",
        "ax1.set_xlabel('Subsampling Strategy')\n",
        "ax1.set_ylabel('Cross-Validation Accuracy')\n",
        "ax1.set_title('Cross-Validation Performance (Mean Â± Std)')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels(sub_df['config'], rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (mean, std) in enumerate(zip(cv_means, cv_stds)):\n",
        "    ax1.text(i, mean + std + 0.005, f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. Train vs Test accuracy\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "width = 0.35\n",
        "bars1 = ax2.bar(x_pos - width/2, sub_df['train_acc'], width, \n",
        "                label='Training', alpha=0.8, color='skyblue')\n",
        "bars2 = ax2.bar(x_pos + width/2, sub_df['test_acc'], width, \n",
        "                label='Test', alpha=0.8, color='lightcoral')\n",
        "ax2.set_xlabel('Subsampling Strategy')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training vs Test Accuracy')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(sub_df['config'], rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Overfitting gap\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "colors = ['red' if gap > 0.05 else 'orange' if gap > 0.02 else 'green' \n",
        "          for gap in sub_df['gap']]\n",
        "bars3 = ax3.bar(sub_df['config'], sub_df['gap'], color=colors, alpha=0.7)\n",
        "ax3.set_ylabel('Overfitting Gap')\n",
        "ax3.set_title('Overfitting Gap by Strategy')\n",
        "ax3.set_xticklabels(sub_df['config'], rotation=45, ha='right')\n",
        "ax3.axhline(y=0.05, color='red', linestyle='--', alpha=0.5)\n",
        "ax3.axhline(y=0.02, color='orange', linestyle='--', alpha=0.5)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Box plot of CV scores\n",
        "cv_data = [result['cv_scores'] for result in subsample_results]\n",
        "bp = ax4.boxplot(cv_data, labels=sub_df['config'], patch_artist=True)\n",
        "colors = ['lightgray', 'lightblue', 'lightgreen', 'gold']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "ax4.set_ylabel('Cross-Validation Accuracy')\n",
        "ax4.set_title('CV Score Distribution')\n",
        "ax4.set_xticklabels(sub_df['config'], rotation=45, ha='right')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“ˆ Subsampling Analysis:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_cv = sub_df.loc[sub_df['cv_mean'].idxmax()]\n",
        "best_test = sub_df.loc[sub_df['test_acc'].idxmax()]\n",
        "lowest_gap = sub_df.loc[sub_df['gap'].idxmin()]\n",
        "\n",
        "print(f\"ðŸ† Best CV Performance: {best_cv['config']}\")\n",
        "print(f\"   CV Score: {best_cv['cv_mean']:.4f} Â± {best_cv['cv_std']:.4f}\")\n",
        "print(f\"   Test Accuracy: {best_cv['test_acc']:.4f}\")\n",
        "print(f\"   Overfitting Gap: {best_cv['gap']:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Best Test Performance: {best_test['config']}\")\n",
        "print(f\"   Test Accuracy: {best_test['test_acc']:.4f}\")\n",
        "print(f\"   CV Score: {best_test['cv_mean']:.4f} Â± {best_test['cv_std']:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ›¡ï¸ Lowest Overfitting: {lowest_gap['config']}\")\n",
        "print(f\"   Overfitting Gap: {lowest_gap['gap']:.4f}\")\n",
        "print(f\"   Test Accuracy: {lowest_gap['test_acc']:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ’¡ Key Insights:\")\n",
        "print(f\"   â€¢ Row subsampling reduces overfitting but may hurt performance\")\n",
        "print(f\"   â€¢ Column subsampling adds randomness and feature selection\")\n",
        "print(f\"   â€¢ Level subsampling provides fine-grained randomness\")\n",
        "print(f\"   â€¢ Moderate subsampling (0.7-0.8) often optimal\")\n",
        "print(f\"   â€¢ Too aggressive subsampling hurts both bias and variance\")"
      ],
      "id": "6cfdf1bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combined Techniques: The Ultimate XGBoost Model ðŸš€\n",
        "\n",
        "Let's combine all techniques for the most robust model possible!\n"
      ],
      "id": "13f6ce22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ultimate XGBoost model combining all techniques\n",
        "print(\"ðŸš€ Building the Ultimate XGBoost Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Use a challenging dataset\n",
        "np.random.seed(42)\n",
        "X_ultimate, y_ultimate = make_classification(\n",
        "    n_samples=3000, n_features=100, \n",
        "    n_informative=30, n_redundant=20,\n",
        "    n_clusters_per_class=3, flip_y=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_ult, X_test_ult, y_train_ult, y_test_ult = train_test_split(\n",
        "    X_ultimate, y_ultimate, test_size=0.2, random_state=42, stratify=y_ultimate\n",
        ")\n",
        "\n",
        "# Define models to compare\n",
        "models_to_compare = {\n",
        "    'Baseline': {\n",
        "        'n_estimators': 100,\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.3,\n",
        "        'subsample': 1.0,\n",
        "        'colsample_bytree': 1.0,\n",
        "        'reg_alpha': 0,\n",
        "        'reg_lambda': 1\n",
        "    },\n",
        "    \n",
        "    'With Regularization': {\n",
        "        'n_estimators': 100,\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.3,\n",
        "        'subsample': 1.0,\n",
        "        'colsample_bytree': 1.0,\n",
        "        'reg_alpha': 5,\n",
        "        'reg_lambda': 5\n",
        "    },\n",
        "    \n",
        "    'With Subsampling': {\n",
        "        'n_estimators': 100,\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.3,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'reg_alpha': 0,\n",
        "        'reg_lambda': 1\n",
        "    },\n",
        "    \n",
        "    'Ultimate Model': {\n",
        "        'n_estimators': 200,\n",
        "        'max_depth': 5,\n",
        "        'learning_rate': 0.1,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'colsample_bylevel': 0.9,\n",
        "        'reg_alpha': 3,\n",
        "        'reg_lambda': 3,\n",
        "        'gamma': 1,\n",
        "        'min_child_weight': 3\n",
        "    }\n",
        "}\n",
        "\n",
        "# Compare models using cross-validation\n",
        "comparison_results = []\n",
        "\n",
        "for model_name, params in models_to_compare.items():\n",
        "    print(f\"ðŸ”„ Evaluating {model_name}...\")\n",
        "    \n",
        "    model = xgb.XGBClassifier(\n",
        "        **params,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # 5-fold cross-validation\n",
        "    cv_scores = cross_val_score(\n",
        "        model, X_train_ult, y_train_ult,\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # Train on full training set for final evaluation\n",
        "    model.fit(X_train_ult, y_train_ult)\n",
        "    train_acc = model.score(X_train_ult, y_train_ult)\n",
        "    test_acc = model.score(X_test_ult, y_test_ult)\n",
        "    \n",
        "    # Store results\n",
        "    comparison_results.append({\n",
        "        'model': model_name,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'train_acc': train_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'gap': train_acc - test_acc,\n",
        "        'cv_scores': cv_scores\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "comp_df = pd.DataFrame(comparison_results)\n",
        "print(\"\\nðŸ“Š Model Comparison Results:\")\n",
        "print(comp_df[['model', 'cv_mean', 'cv_std', 'train_acc', 'test_acc', 'gap']].round(4))\n",
        "\n",
        "# Visualization\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Cross-validation scores with error bars\n",
        "models = comp_df['model']\n",
        "cv_means = comp_df['cv_mean']\n",
        "cv_stds = comp_df['cv_std']\n",
        "\n",
        "bars = ax1.bar(models, cv_means, yerr=cv_stds, capsize=5, \n",
        "               alpha=0.8, color=['gray', 'blue', 'green', 'gold'])\n",
        "ax1.set_ylabel('Cross-Validation Accuracy')\n",
        "ax1.set_title('Cross-Validation Performance Comparison')\n",
        "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (mean, std) in enumerate(zip(cv_means, cv_stds)):\n",
        "    ax1.text(i, mean + std + 0.005, f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. Train vs Test accuracy\n",
        "x_pos = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax2.bar(x_pos - width/2, comp_df['train_acc'], width, \n",
        "                label='Training', alpha=0.8, color='skyblue')\n",
        "bars2 = ax2.bar(x_pos + width/2, comp_df['test_acc'], width, \n",
        "                label='Test', alpha=0.8, color='lightcoral')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training vs Test Accuracy')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(models, rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Overfitting gap\n",
        "ax3.bar(models, comp_df['gap'], color='red', alpha=0.7)\n",
        "ax3.set_ylabel('Overfitting Gap (Train - Test)')\n",
        "ax3.set_title('Overfitting Comparison')\n",
        "ax3.set_xticklabels(models, rotation=45, ha='right')\n",
        "ax3.axhline(y=0.05, color='red', linestyle='--', alpha=0.5)\n",
        "ax3.axhline(y=0.02, color='red', linestyle='--', alpha=0.5)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Box plot of CV scores\n",
        "cv_data = [result['cv_scores'] for result in comparison_results]\n",
        "bp = ax4.boxplot(cv_data, labels=models, patch_artist=True)\n",
        "colors = ['lightgray', 'lightblue', 'lightgreen', 'gold']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "ax4.set_ylabel('Cross-Validation Accuracy')\n",
        "ax4.set_title('CV Score Distribution')\n",
        "ax4.set_xticklabels(models, rotation=45, ha='right')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final analysis\n",
        "print(f\"\\nðŸ† FINAL RESULTS:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_model = comp_df.loc[comp_df['test_acc'].idxmax()]\n",
        "lowest_gap = comp_df.loc[comp_df['gap'].idxmin()]\n",
        "\n",
        "print(f\"ðŸ¥‡ Best Overall Performance: {best_model['model']}\")\n",
        "print(f\"   Test Accuracy: {best_model['test_acc']:.4f}\")\n",
        "print(f\"   CV Score: {best_model['cv_mean']:.4f} Â± {best_model['cv_std']:.4f}\")\n",
        "print(f\"   Overfitting Gap: {best_model['gap']:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ›¡ï¸ Best Generalization: {lowest_gap['model']}\")\n",
        "print(f\"   Overfitting Gap: {lowest_gap['gap']:.4f}\")\n",
        "print(f\"   Test Accuracy: {lowest_gap['test_acc']:.4f}\")\n",
        "\n",
        "# Calculate improvements\n",
        "baseline_test = comp_df[comp_df['model'] == 'Baseline']['test_acc'].iloc[0]\n",
        "ultimate_test = comp_df[comp_df['model'] == 'Ultimate Model']['test_acc'].iloc[0]\n",
        "improvement = ((ultimate_test - baseline_test) / baseline_test) * 100\n",
        "\n",
        "baseline_gap = comp_df[comp_df['model'] == 'Baseline']['gap'].iloc[0]\n",
        "ultimate_gap = comp_df[comp_df['model'] == 'Ultimate Model']['gap'].iloc[0]\n",
        "gap_reduction = ((baseline_gap - ultimate_gap) / baseline_gap) * 100\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Ultimate Model Improvements:\")\n",
        "print(f\"   Test Accuracy Improvement: {improvement:.1f}%\")\n",
        "print(f\"   Overfitting Reduction: {gap_reduction:.1f}%\")\n",
        "print(f\"   More Robust: Lower CV standard deviation\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Key Takeaways:\")\n",
        "print(f\"   âœ… Regularization prevents overfitting\")\n",
        "print(f\"   âœ… Subsampling adds beneficial randomness\")\n",
        "print(f\"   âœ… Cross-validation provides reliable estimates\")\n",
        "print(f\"   âœ… Combined techniques work synergistically\")\n",
        "print(f\"   âœ… Slower learning (lr=0.1) with more trees often better\")"
      ],
      "id": "10e4aac4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You've successfully completed a comprehensive XGBoost learning journey! Here's what you've learned:\n",
        "\n",
        "### Theory & Fundamentals:\n",
        "âœ… How gradient boosting works  \n",
        "âœ… XGBoost's improvements over traditional boosting  \n",
        "âœ… Key parameters and their effects  \n",
        "âœ… Regularization and overfitting prevention  \n",
        "\n",
        "### Practical Skills:\n",
        "âœ… Data preprocessing and feature engineering  \n",
        "âœ… Model training and hyperparameter tuning  \n",
        "âœ… Model evaluation with multiple metrics  \n",
        "âœ… Business application and decision-making  \n",
        "\n",
        "### Next Steps:\n",
        "1. Try XGBoost on your own datasets\n",
        "2. Experiment with different objective functions\n",
        "3. Explore XGBoost's advanced features (custom objectives, callbacks)\n",
        "4. Learn about SHAP values for model interpretation\n",
        "5. Compare with LightGBM and CatBoost\n",
        "\n",
        "Happy modeling! ðŸš€\n",
        "\n",
        "## ðŸ“š Additional Exercises for Practice\n",
        "\n",
        "1. **Feature Selection**: Use XGBoost's feature importance to select top features and retrain\n",
        "2. **Class Imbalance**: Experiment with `scale_pos_weight` parameter\n",
        "3. **Custom Metrics**: Implement a custom evaluation metric for business cost\n",
        "4. **Ensemble Methods**: Combine XGBoost with other models\n",
        "5. **Time Series**: Apply XGBoost to time-series prediction\n"
      ],
      "id": "05e90be6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save the model for deployment\n",
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "# joblib.dump(final_model, 'credit_risk_xgboost_model.pkl')\n",
        "# print(\"âœ… Model saved successfully!\")\n",
        "\n",
        "# Example: Loading and using the saved model\n",
        "# loaded_model = joblib.load('credit_risk_xgboost_model.pkl')\n",
        "# new_predictions = loaded_model.predict(new_data)"
      ],
      "id": "74c37ea4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ],
      "id": "59fff67b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Hands-On Project ðŸ—ï¸\n",
        "\n",
        "## Credit Risk Assessment Model\n",
        "\n",
        "Now let's apply everything we've learned to build a real-world credit risk model!\n",
        "\n",
        "**Scenario**: You work for a bank and need to predict whether loan applicants will default.\n",
        "\n",
        "**Goal**: Build an XGBoost model that can accurately identify high-risk applicants while minimizing false rejections of good customers.\n",
        "\n",
        "## Step 1: Data Generation and Understanding ðŸ“Š\n",
        "\n",
        "First, let's create a realistic credit dataset with meaningful features."
      ],
      "id": "69366f43"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate synthetic credit data\n",
        "np.random.seed(42)\n",
        "n_customers = 10000\n",
        "\n",
        "# Create realistic features\n",
        "credit_data = pd.DataFrame({\n",
        "    # Demographics\n",
        "    'age': np.random.normal(40, 12, n_customers).clip(18, 80).astype(int),\n",
        "    'income': np.random.lognormal(10.5, 0.6, n_customers),\n",
        "    'employment_years': np.random.exponential(7, n_customers).clip(0, 40),\n",
        "    \n",
        "    # Credit history\n",
        "    'credit_score': np.random.normal(700, 100, n_customers).clip(300, 850).astype(int),\n",
        "    'num_credit_cards': np.random.poisson(3, n_customers),\n",
        "    'num_loans': np.random.poisson(2, n_customers),\n",
        "    \n",
        "    # Current loan details\n",
        "    'loan_amount': np.random.lognormal(10, 0.8, n_customers),\n",
        "    'loan_term_months': np.random.choice([12, 24, 36, 48, 60], n_customers),\n",
        "    'interest_rate': np.random.normal(10, 3, n_customers).clip(3, 20),\n",
        "    \n",
        "    # Financial behavior\n",
        "    'debt_to_income': np.random.beta(2, 5, n_customers) * 0.8,\n",
        "    'missed_payments': np.random.poisson(0.5, n_customers),\n",
        "    'credit_utilization': np.random.beta(2, 5, n_customers),\n",
        "    \n",
        "    # Account information\n",
        "    'checking_balance': np.random.lognormal(8, 1.5, n_customers),\n",
        "    'savings_balance': np.random.lognormal(9, 1.8, n_customers),\n",
        "    'months_since_last_delinquent': np.random.exponential(24, n_customers).clip(0, 100)\n",
        "})\n",
        "\n",
        "# Create realistic default probability based on features\n",
        "default_probability = (\n",
        "    0.05 +  # Base rate\n",
        "    0.15 * (credit_data['credit_score'] < 600) +\n",
        "    0.10 * (credit_data['debt_to_income'] > 0.4) +\n",
        "    0.10 * (credit_data['missed_payments'] > 2) +\n",
        "    0.08 * (credit_data['credit_utilization'] > 0.8) +\n",
        "    0.07 * (credit_data['income'] < 30000) +\n",
        "    0.05 * (credit_data['checking_balance'] < 1000) +\n",
        "    0.05 * (credit_data['employment_years'] < 1) +\n",
        "    np.random.normal(0, 0.05, n_customers)\n",
        ").clip(0, 1)\n",
        "\n",
        "# Generate default labels\n",
        "credit_data['default'] = (np.random.random(n_customers) < default_probability).astype(int)\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"ðŸ“Š Dataset Overview:\")\n",
        "print(f\"Total customers: {len(credit_data):,}\")\n",
        "print(f\"Default rate: {credit_data['default'].mean():.1%}\")\n",
        "print(\"\\nðŸ“ˆ Feature Statistics:\")\n",
        "print(credit_data.describe())"
      ],
      "id": "27a69d45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Exploratory Data Analysis (EDA) ðŸ”\n",
        "\n",
        "Let's understand our data better through visualization."
      ],
      "id": "7f1126da"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EDA visualizations\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# 1. Default rate distribution\n",
        "credit_data['default'].value_counts().plot(kind='bar', ax=axes[0], color=['green', 'red'])\n",
        "axes[0].set_title('Default Distribution')\n",
        "axes[0].set_xticklabels(['No Default', 'Default'], rotation=0)\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "# 2. Credit score by default status\n",
        "credit_data.boxplot(column='credit_score', by='default', ax=axes[1])\n",
        "axes[1].set_title('Credit Score by Default Status')\n",
        "axes[1].set_xticklabels(['No Default', 'Default'])\n",
        "\n",
        "# 3. Income distribution by default\n",
        "credit_data[credit_data['income'] < 200000].boxplot(column='income', by='default', ax=axes[2])\n",
        "axes[2].set_title('Income by Default Status')\n",
        "axes[2].set_xticklabels(['No Default', 'Default'])\n",
        "\n",
        "# 4. Debt-to-income ratio\n",
        "credit_data.boxplot(column='debt_to_income', by='default', ax=axes[3])\n",
        "axes[3].set_title('Debt-to-Income Ratio')\n",
        "axes[3].set_xticklabels(['No Default', 'Default'])\n",
        "\n",
        "# 5. Missed payments impact\n",
        "missed_payments_default = credit_data.groupby('missed_payments')['default'].mean()\n",
        "missed_payments_default.plot(kind='bar', ax=axes[4], color='orange')\n",
        "axes[4].set_title('Default Rate by Missed Payments')\n",
        "axes[4].set_xlabel('Number of Missed Payments')\n",
        "axes[4].set_ylabel('Default Rate')\n",
        "\n",
        "# 6. Feature correlation heatmap\n",
        "numeric_cols = ['credit_score', 'income', 'debt_to_income', 'missed_payments', \n",
        "                'credit_utilization', 'default']\n",
        "correlation_matrix = credit_data[numeric_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[5], \n",
        "            fmt='.2f', square=True)\n",
        "axes[5].set_title('Feature Correlations')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b748b2e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Key Insights:\n",
        "- Credit score is strongly correlated with default (negative correlation)\n",
        "- Missed payments are a strong indicator of default\n",
        "- Debt-to-income ratio affects default probability\n",
        "- Income alone is not a strong predictor\n",
        "\n",
        "## Step 3: Feature Engineering ðŸ”§\n",
        "\n",
        "Let's create some powerful features that might help our model."
      ],
      "id": "e77961fb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature engineering\n",
        "credit_data_eng = credit_data.copy()\n",
        "\n",
        "# Create new features\n",
        "credit_data_eng['loan_to_income_ratio'] = credit_data_eng['loan_amount'] / credit_data_eng['income']\n",
        "credit_data_eng['total_debt'] = credit_data_eng['debt_to_income'] * credit_data_eng['income']\n",
        "credit_data_eng['monthly_payment'] = (credit_data_eng['loan_amount'] * \n",
        "                                      (credit_data_eng['interest_rate'] / 100 / 12)) / \\\n",
        "                                     (1 - (1 + credit_data_eng['interest_rate'] / 100 / 12) ** \n",
        "                                      (-credit_data_eng['loan_term_months']))\n",
        "credit_data_eng['payment_to_income'] = credit_data_eng['monthly_payment'] / (credit_data_eng['income'] / 12)\n",
        "credit_data_eng['financial_health_score'] = (\n",
        "    credit_data_eng['credit_score'] / 850 * 0.3 +\n",
        "    (1 - credit_data_eng['debt_to_income']) * 0.3 +\n",
        "    (1 - credit_data_eng['credit_utilization']) * 0.2 +\n",
        "    np.log1p(credit_data_eng['savings_balance']) / 15 * 0.2\n",
        ")\n",
        "credit_data_eng['risk_category'] = pd.cut(\n",
        "    credit_data_eng['credit_score'], \n",
        "    bins=[0, 580, 670, 740, 850],\n",
        "    labels=['Poor', 'Fair', 'Good', 'Excellent']\n",
        ")\n",
        "\n",
        "# Show new features\n",
        "print(\"ðŸ”§ New engineered features:\")\n",
        "new_features = ['loan_to_income_ratio', 'total_debt', 'monthly_payment', \n",
        "                'payment_to_income', 'financial_health_score']\n",
        "print(credit_data_eng[new_features].describe())"
      ],
      "id": "a370b3e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Data Preprocessing ðŸ§¹\n",
        "\n",
        "Prepare the data for XGBoost modeling."
      ],
      "id": "3fdde86a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocessing\n",
        "# Handle categorical variables\n",
        "categorical_cols = ['risk_category']\n",
        "credit_data_encoded = pd.get_dummies(credit_data_eng, columns=categorical_cols, prefix='risk')\n",
        "\n",
        "# Separate features and target\n",
        "feature_cols = [col for col in credit_data_encoded.columns if col not in ['default']]\n",
        "X = credit_data_encoded[feature_cols]\n",
        "y = credit_data_encoded['default']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(\"ðŸ”„ Data split:\")\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]:,} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
        "print(f\"\\nDefault rates:\")\n",
        "print(f\"Train: {y_train.mean():.1%}\")\n",
        "print(f\"Validation: {y_val.mean():.1%}\")\n",
        "print(f\"Test: {y_test.mean():.1%}\")"
      ],
      "id": "ab5ec489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Baseline Model ðŸ“Š\n",
        "\n",
        "Let's start with a simple XGBoost model to establish a baseline."
      ],
      "id": "74a5d6e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Baseline model\n",
        "baseline_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='auc',\n",
        "    random_state=42,\n",
        "    n_estimators=100\n",
        ")\n",
        "\n",
        "# Train\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_baseline = baseline_model.predict(X_test)\n",
        "y_pred_proba_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
        "\n",
        "baseline_auc = roc_auc_score(y_test, y_pred_proba_baseline)\n",
        "baseline_ap = average_precision_score(y_test, y_pred_proba_baseline)\n",
        "\n",
        "print(\"ðŸ“Š Baseline Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.3f}\")\n",
        "print(f\"ROC AUC: {baseline_auc:.3f}\")\n",
        "print(f\"Average Precision: {baseline_ap:.3f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_baseline, target_names=['No Default', 'Default']))"
      ],
      "id": "d70bbe9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Hyperparameter Optimization ðŸŽ¯\n",
        "\n",
        "Now let's optimize our model using systematic hyperparameter tuning."
      ],
      "id": "d565cc9e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define parameter grid for optimization\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 1, 5],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [1, 2, 5]\n",
        "}\n",
        "\n",
        "# Use a smaller grid for demonstration (full grid would take too long)\n",
        "param_grid_small = {\n",
        "    'max_depth': [5, 7],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.8],\n",
        "    'gamma': [0, 1]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "xgb_classifier = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='auc',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    xgb_classifier,\n",
        "    param_grid_small,\n",
        "    cv=3,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"ðŸ” Performing hyperparameter search...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nâœ… Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"ðŸ“ˆ Best cross-validation score: {grid_search.best_score_:.3f}\")"
      ],
      "id": "4b5506ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Final Model Training with Advanced Features ðŸ†"
      ],
      "id": "5f9944d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train final model with best parameters and advanced features\n",
        "final_model = xgb.XGBClassifier(\n",
        "    **grid_search.best_params_,\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='auc',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model (early stopping removed for version compatibility)\n",
        "# In production, configure early stopping based on your XGBoost version\n",
        "final_model.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "# Get predictions\n",
        "y_pred_final = final_model.predict(X_test)\n",
        "y_pred_proba_final = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "final_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
        "final_ap = average_precision_score(y_test, y_pred_proba_final)\n",
        "\n",
        "print(\"ðŸ† Final Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_final):.3f}\")\n",
        "print(f\"ROC AUC: {final_auc:.3f} (Improvement: {(final_auc - baseline_auc) / baseline_auc * 100:.1f}%)\")\n",
        "print(f\"Average Precision: {final_ap:.3f}\")"
      ],
      "id": "32f89b87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Model Interpretation and Business Insights ðŸ’¡"
      ],
      "id": "10c29a60"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comprehensive model evaluation\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': final_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False).head(15)\n",
        "\n",
        "axes[0, 0].barh(feature_importance['feature'][::-1], feature_importance['importance'][::-1])\n",
        "axes[0, 0].set_xlabel('Importance')\n",
        "axes[0, 0].set_title('Top 15 Most Important Features')\n",
        "\n",
        "# 2. Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Confusion Matrix')\n",
        "axes[0, 1].set_xlabel('Predicted')\n",
        "axes[0, 1].set_ylabel('Actual')\n",
        "axes[0, 1].set_xticklabels(['No Default', 'Default'])\n",
        "axes[0, 1].set_yticklabels(['No Default', 'Default'])\n",
        "\n",
        "# 3. ROC Curve\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_final)\n",
        "axes[1, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {final_auc:.3f})')\n",
        "axes[1, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "axes[1, 0].set_xlim([0.0, 1.0])\n",
        "axes[1, 0].set_ylim([0.0, 1.05])\n",
        "axes[1, 0].set_xlabel('False Positive Rate')\n",
        "axes[1, 0].set_ylabel('True Positive Rate')\n",
        "axes[1, 0].set_title('ROC Curve')\n",
        "axes[1, 0].legend(loc=\"lower right\")\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba_final)\n",
        "axes[1, 1].plot(recall, precision, color='darkgreen', lw=2, label=f'AP = {final_ap:.3f}')\n",
        "axes[1, 1].set_xlabel('Recall')\n",
        "axes[1, 1].set_ylabel('Precision')\n",
        "axes[1, 1].set_title('Precision-Recall Curve')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "60fcad96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Business Application - Risk Scoring ðŸ’¼"
      ],
      "id": "98810a29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a risk scoring system\n",
        "# Define risk categories based on predicted probabilities\n",
        "risk_thresholds = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "risk_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
        "\n",
        "# Apply to test set\n",
        "test_results = pd.DataFrame({\n",
        "    'true_default': y_test,\n",
        "    'predicted_probability': y_pred_proba_final,\n",
        "    'risk_category': pd.cut(y_pred_proba_final, bins=risk_thresholds, labels=risk_labels)\n",
        "})\n",
        "\n",
        "# Analyze risk categories\n",
        "risk_analysis = test_results.groupby('risk_category').agg({\n",
        "    'true_default': ['count', 'sum', 'mean']\n",
        "}).round(3)\n",
        "risk_analysis.columns = ['Count', 'Defaults', 'Default_Rate']\n",
        "\n",
        "print(\"ðŸ“Š Risk Category Analysis:\")\n",
        "print(risk_analysis)\n",
        "\n",
        "# Visualize risk distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Risk category distribution\n",
        "test_results['risk_category'].value_counts().plot(kind='bar', ax=ax1, color='skyblue')\n",
        "ax1.set_title('Distribution of Customers by Risk Category')\n",
        "ax1.set_xlabel('Risk Category')\n",
        "ax1.set_ylabel('Number of Customers')\n",
        "\n",
        "# Default rate by risk category\n",
        "risk_analysis['Default_Rate'].plot(kind='bar', ax=ax2, color='coral')\n",
        "ax2.set_title('Actual Default Rate by Risk Category')\n",
        "ax2.set_xlabel('Risk Category')\n",
        "ax2.set_ylabel('Default Rate')\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(risk_analysis['Default_Rate']):\n",
        "    ax2.text(i, v + 0.01, f'{v:.1%}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "4cf4e0bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Making Business Decisions ðŸ“ˆ\n",
        "\n",
        "Let's simulate how the bank would use this model to make lending decisions."
      ],
      "id": "05003a40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Business simulation\n",
        "# Calculate potential profit/loss for different threshold strategies\n",
        "\n",
        "# Business parameters\n",
        "loan_profit_rate = 0.05  # 5% profit on successful loans\n",
        "default_loss_rate = 0.30  # 30% loss on defaulted loans\n",
        "\n",
        "# Test different approval thresholds\n",
        "thresholds = np.arange(0.1, 0.7, 0.05)\n",
        "business_results = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    # Approve loans below threshold\n",
        "    approved = y_pred_proba_final < threshold\n",
        "    \n",
        "    # Calculate business metrics\n",
        "    n_approved = approved.sum()\n",
        "    n_defaults = ((y_test == 1) & approved).sum()\n",
        "    n_successful = n_approved - n_defaults\n",
        "    \n",
        "    # Calculate profit/loss\n",
        "    profit = n_successful * loan_profit_rate - n_defaults * default_loss_rate\n",
        "    approval_rate = n_approved / len(y_test)\n",
        "    default_rate_approved = n_defaults / n_approved if n_approved > 0 else 0\n",
        "    \n",
        "    business_results.append({\n",
        "        'threshold': threshold,\n",
        "        'approval_rate': approval_rate,\n",
        "        'default_rate': default_rate_approved,\n",
        "        'profit_per_100_loans': profit / len(y_test) * 100\n",
        "    })\n",
        "\n",
        "business_df = pd.DataFrame(business_results)\n",
        "\n",
        "# Find optimal threshold\n",
        "optimal_idx = business_df['profit_per_100_loans'].idxmax()\n",
        "optimal_threshold = business_df.loc[optimal_idx, 'threshold']\n",
        "\n",
        "# Visualize business impact\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Approval rate vs default rate\n",
        "ax1.plot(business_df['threshold'], business_df['approval_rate'], 'b-', label='Approval Rate')\n",
        "ax1.plot(business_df['threshold'], business_df['default_rate'], 'r-', label='Default Rate (Approved)')\n",
        "ax1.axvline(x=optimal_threshold, color='green', linestyle='--', label=f'Optimal ({optimal_threshold:.2f})')\n",
        "ax1.set_xlabel('Risk Threshold')\n",
        "ax1.set_ylabel('Rate')\n",
        "ax1.set_title('Approval and Default Rates by Threshold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Profit curve\n",
        "ax2.plot(business_df['threshold'], business_df['profit_per_100_loans'], 'g-', linewidth=2)\n",
        "ax2.axvline(x=optimal_threshold, color='green', linestyle='--', label=f'Optimal ({optimal_threshold:.2f})')\n",
        "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "ax2.set_xlabel('Risk Threshold')\n",
        "ax2.set_ylabel('Profit per 100 Loans')\n",
        "ax2.set_title('Expected Profit by Risk Threshold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ðŸ’° Optimal Strategy:\")\n",
        "print(f\"Risk threshold: {optimal_threshold:.2f}\")\n",
        "print(f\"Approval rate: {business_df.loc[optimal_idx, 'approval_rate']:.1%}\")\n",
        "print(f\"Default rate among approved: {business_df.loc[optimal_idx, 'default_rate']:.1%}\")\n",
        "print(f\"Expected profit per 100 loans: ${business_df.loc[optimal_idx, 'profit_per_100_loans']:.2f}\")"
      ],
      "id": "48b576b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Additional Exercises for Practice\n",
        "\n",
        "1. **Feature Selection**: Use XGBoost's feature importance to select top features and retrain\n",
        "2. **Class Imbalance**: Experiment with `scale_pos_weight` parameter\n",
        "3. **Custom Metrics**: Implement a custom evaluation metric for business cost\n",
        "4. **Ensemble Methods**: Combine XGBoost with other models\n",
        "5. **Time Series**: Apply XGBoost to time-series prediction"
      ],
      "id": "d3d0376b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save the model for deployment\n",
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "# joblib.dump(final_model, 'credit_risk_xgboost_model.pkl')\n",
        "# print(\"âœ… Model saved successfully!\")\n",
        "\n",
        "# Example: Loading and using the saved model\n",
        "# loaded_model = joblib.load('credit_risk_xgboost_model.pkl')\n",
        "# new_predictions = loaded_model.predict(new_data)"
      ],
      "id": "71736ff9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}