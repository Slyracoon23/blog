<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Earl Potters">
<meta name="dcterms.date" content="2025-03-21">

<title>EleutherAI’s lm-evaluation-harness: Architecture and Configuration – Earl Potters</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="..//images/favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-46f4cc9626f044588a66931b604fc9c8.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-86ca98530662af5ddd08d363d7d219b9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-4DWYJM47PC"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-4DWYJM47PC', { 'anonymize_ip': true});
</script>
<script src="../assets/citations.js"></script>
<script>
    !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey canRenderSurveyAsync identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
    posthog.init('phc_3LFGZh7SWQGVrh5GwvDO3qwdESpdJb9AnpJHks39zdA', {
        api_host: 'https://us.i.posthog.com',
        person_profiles: 'always',
    })
</script>


<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="../assets/citations.css">
<meta property="og:title" content="EleutherAI’s lm-evaluation-harness: Architecture and Configuration – Earl Potters">
<meta property="og:description" content="A comprehensive guide to configuration, task architecture, and model integration">
<meta property="og:image" content="https://i.imgur.com/OhBrtWj.png">
<meta property="og:site_name" content="Earl Potters">
<meta name="twitter:title" content="EleutherAI’s lm-evaluation-harness: Architecture and Configuration – Earl Potters">
<meta name="twitter:description" content="A comprehensive guide to configuration, task architecture, and model integration">
<meta name="twitter:image" content="https://i.imgur.com/OhBrtWj.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Earl Potters</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text"><i class="fa-solid fa-address-card" aria-label="address-card"></i> About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../posts.html"> 
<span class="menu-text"><i class="fa-solid fa-newspaper" aria-label="newspaper"></i> Posts</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/SRacoon23"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/earl-potters-b2b306187/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Slyracoon23"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://huggingface.co/Slyracoon23"> 
<span class="menu-text"><img src="https://mlabonne.github.io/blog/images/hf-icon.svg" class="img-fluid"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../posts/2025-02-19_building_chatgpt_from_scratch.html">🗣️ <strong>Large Language Models</strong></a></li><li class="breadcrumb-item"><a href="../posts/2025-03-21_eleutherai-evaluation-methods.html">EleutherAI’s lm-evaluation-harness</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../posts/2025-02-19_building_chatgpt_from_scratch.html">🗣️ <strong>Large Language Models</strong></a></li><li class="breadcrumb-item"><a href="../posts/2025-03-21_eleutherai-evaluation-methods.html">EleutherAI’s lm-evaluation-harness</a></li></ol></nav>
      <h1 class="title">EleutherAI’s lm-evaluation-harness: Architecture and Configuration</h1>
            <p class="subtitle lead">A comprehensive guide to configuration, task architecture, and model integration</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Large Language Models</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Earl Potters </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 21, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">🤖 <strong>AI Agents</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-03_what_is_an_agent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is an AI Agent?</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">🗣️ <strong>Large Language Models</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-02-19_building_chatgpt_from_scratch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building ChatGPT from Scratch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-15_what_is_prompt_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is Prompt Engineering?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-16_what_are_image_embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What are Image Embeddings?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-18_exploring_gemma_3_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploring Gemma 3 Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-21_eleutherai-evaluation-methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">EleutherAI’s lm-evaluation-harness</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-04-05_model_context_protocol_tool_poisoning_attacks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Context Protocol Tool Poisoning Attacks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-04-27_gemini-image-segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gemini Image Segmentation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-05-04_game_of_ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A Game of Ethics: Quantifying AI Moral Reasoning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">🌐 <strong>Web Technologies</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-14_what_is_rrweb.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is rrweb?</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">🗄️ <strong>Databases</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-04-19_sql_query_performance_postgres.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Measure SQL Query Performance on Postgres</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">📝 <strong>Writing &amp; Content</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-24_how_to_stop_being_accused_of_ai_slop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Stop Being Accused of AI Slop</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title"><strong>Sections</strong></h2>
   
  <ul class="collapse">
  <li><a href="#what-is-lm-evaluation-harness" id="toc-what-is-lm-evaluation-harness" class="nav-link active" data-scroll-target="#what-is-lm-evaluation-harness">What is lm-evaluation-harness?</a></li>
  <li><a href="#installation-options" id="toc-installation-options" class="nav-link" data-scroll-target="#installation-options">Installation Options</a></li>
  <li><a href="#command-line-usage" id="toc-command-line-usage" class="nav-link" data-scroll-target="#command-line-usage">Command Line Usage</a></li>
  <li><a href="#model-configuration" id="toc-model-configuration" class="nav-link" data-scroll-target="#model-configuration">Model Configuration</a></li>
  <li><a href="#task-configuration" id="toc-task-configuration" class="nav-link" data-scroll-target="#task-configuration">Task Configuration</a></li>
  <li><a href="#advanced-features" id="toc-advanced-features" class="nav-link" data-scroll-target="#advanced-features">Advanced Features</a></li>
  <li><a href="#creating-custom-tasks" id="toc-creating-custom-tasks" class="nav-link" data-scroll-target="#creating-custom-tasks">Creating Custom Tasks</a></li>
  <li><a href="#best-practices-and-common-pitfalls" id="toc-best-practices-and-common-pitfalls" class="nav-link" data-scroll-target="#best-practices-and-common-pitfalls">Best Practices and Common Pitfalls</a></li>
  <li><a href="#adding-new-models-to-the-framework" id="toc-adding-new-models-to-the-framework" class="nav-link" data-scroll-target="#adding-new-models-to-the-framework">Adding New Models to the Framework</a></li>
  <li><a href="#practical-examples" id="toc-practical-examples" class="nav-link" data-scroll-target="#practical-examples">Practical Examples</a></li>
  <li><a href="#contributing-to-lm-evaluation-harness" id="toc-contributing-to-lm-evaluation-harness" class="nav-link" data-scroll-target="#contributing-to-lm-evaluation-harness">Contributing to lm-evaluation-harness</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/OhBrtWj.png" class="img-fluid figure-img"></p>
<figcaption>EleutherAI’s lm-evaluation-harness architecture diagram showing the relationship between models, tasks, and evaluation metrics</figcaption>
</figure>
</div>
<p>EleutherAI’s <a href="https://github.com/EleutherAI/lm-evaluation-harness">lm-evaluation-harness</a> has emerged as one of the most robust and comprehensive frameworks for evaluating language models. Used by organizations including NVIDIA, Cohere, BigScience, and Mosaic ML, it serves as the backend for Hugging Face’s Open LLM Leaderboard and has been cited in hundreds of research papers.</p>
<p>This post explores the framework’s architecture, configuration system, and integration patterns to help you understand how to use, extend, and contribute to this powerful evaluation ecosystem.</p>
<section id="what-is-lm-evaluation-harness" class="level2">
<h2 class="anchored" data-anchor-id="what-is-lm-evaluation-harness">What is lm-evaluation-harness?</h2>
<p>The Language Model Evaluation Harness is a unified framework for testing generative language models on a wide variety of benchmarks. It ensures reproducibility by using publicly available prompts and supports customized evaluations.</p>
<p>Key features include:</p>
<ul>
<li>Over 60 standard academic benchmarks with hundreds of subtasks</li>
<li>Support for models via transformers (including quantization via GPTQ), GPT-NeoX, and Megatron-DeepSpeed</li>
<li>Fast inference with vLLM</li>
<li>Support for commercial APIs (OpenAI, TextSynth)</li>
<li>Evaluation on adapter models (like LoRA) through PEFT</li>
<li>Support for local models and benchmarks</li>
<li>Customizable prompts and metrics</li>
</ul>
</section>
<section id="installation-options" class="level2">
<h2 class="anchored" data-anchor-id="installation-options">Installation Options</h2>
<section id="basic-installation" class="level3">
<h3 class="anchored" data-anchor-id="basic-installation">Basic Installation</h3>
<p>Basic installation from source:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone <span class="at">--depth</span> 1 https://github.com/EleutherAI/lm-evaluation-harness</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> lm-evaluation-harness</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-e</span> .</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or install directly from PyPI:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install lm-eval</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="development-installation" class="level3">
<h3 class="anchored" data-anchor-id="development-installation">Development Installation</h3>
<p>For development and contributing:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-e</span> <span class="st">".[dev]"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="optional-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="optional-dependencies">Optional Dependencies</h3>
<p>The framework provides several optional dependency groups:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For GPTQ quantization support</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="st">"lm-eval[gptq]"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For vLLM acceleration</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="st">"lm-eval[vllm]"</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># For multiple optional dependencies</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="st">"lm-eval[gptq,vllm]"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="environment-variables" class="level3">
<h3 class="anchored" data-anchor-id="environment-variables">Environment Variables</h3>
<p>Some functionality requires specific environment variables:</p>
<ul>
<li><code>OPENAI_API_KEY</code> - For evaluating OpenAI models</li>
<li><code>ANTHROPIC_API_KEY</code> - For evaluating Anthropic models</li>
<li><code>HF_TOKEN</code> - For accessing gated Hugging Face models or pushing results to the Hub</li>
<li><code>LOGLEVEL</code> - Set to “DEBUG” for detailed logging during evaluation</li>
</ul>
</section>
</section>
<section id="command-line-usage" class="level2">
<h2 class="anchored" data-anchor-id="command-line-usage">Command Line Usage</h2>
<p>The harness can be run as a command-line tool, providing a flexible interface for model evaluation:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> lm_eval <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=gpt2 <span class="at">--tasks</span> hellaswag <span class="at">--num_fewshot</span> 5</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or using the installed entry point:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=gpt2 <span class="at">--tasks</span> hellaswag <span class="at">--num_fewshot</span> 5</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="common-cli-arguments" class="level3">
<h3 class="anchored" data-anchor-id="common-cli-arguments">Common CLI Arguments</h3>
<ul>
<li><code>--model</code>: Specifies the model type to evaluate (e.g., “hf”, “openai”, “vllm”)</li>
<li><code>--model_args</code>: Parameters for model initialization (e.g., “pretrained=gpt2,dtype=float32”)</li>
<li><code>--tasks</code>: Comma-separated list of tasks or task groups (e.g., “mmlu,hellaswag”)</li>
<li><code>--num_fewshot</code>: Number of few-shot examples to include (default: 0)</li>
<li><code>--batch_size</code>: Batch size for evaluation (use “auto” for automatic selection)</li>
<li><code>--device</code>: Device to place the model on (e.g., “cuda:0”, “cpu”)</li>
<li><code>--output_path</code>: Path to save evaluation results</li>
<li><code>--log_samples</code>: Save per-document outputs and inputs</li>
</ul>
<p>For more detailed information on CLI arguments, see the <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md">interface documentation</a> which covers additional options like:</p>
<ul>
<li><p><code>--cache_requests</code>: Can be “true”, “refresh”, or “delete” to use, regenerate, or remove the cache</p></li>
<li><p><code>--check_integrity</code>: Tests each selected task to confirm integrity</p></li>
<li><p><code>--write_out</code>: Prints prompt and gold target string for the first document of each task (for diagnostics)</p></li>
<li><p><code>--show_config</code>: Prints the full TaskConfig contents for reproducibility</p></li>
<li><p><code>--include_path</code>: Accepts a path to a folder with custom YAML task configurations</p></li>
<li><p><code>--system_instruction</code>: Specifies a system instruction string to prepend to the prompt</p></li>
<li><p><code>--apply_chat_template</code>: Controls whether to apply a chat template to prompts</p></li>
<li><p><code>--fewshot_as_multiturn</code>: Treats few-shot examples as a multi-turn conversation</p></li>
<li><p><code>--predict_only</code>: Generates model outputs without computing metrics</p></li>
<li><p><code>--seed</code>: Sets random seeds for reproducibility</p></li>
</ul>
</section>
<section id="python-api-usage" class="level3">
<h3 class="anchored" data-anchor-id="python-api-usage">Python API Usage</h3>
<p>You can also use the framework programmatically:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lm_eval <span class="im">import</span> evaluator, tasks</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lm_eval.models <span class="im">import</span> get_model</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> get_model(<span class="st">"hf"</span>, pretrained<span class="op">=</span><span class="st">"gpt2"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> evaluator.evaluate(model, tasks<span class="op">=</span>[<span class="st">"hellaswag"</span>], num_fewshot<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For even simpler usage:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> lm_eval</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> lm_eval.simple_evaluate(</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"gpt2"</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    tasks<span class="op">=</span>[<span class="st">"hellaswag"</span>, <span class="st">"mmlu"</span>],</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    num_fewshot<span class="op">=</span><span class="dv">0</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For more advanced usage, the <code>evaluate()</code> function offers the core evaluation functionality, but without some of the special handling and simplification provided by <code>simple_evaluate()</code>. This allows you to:</p>
<ul>
<li>Use custom task implementations</li>
<li>Specify task configurations via dictionaries</li>
<li>Provide a TaskManager with custom included paths</li>
<li>Integrate with your own model training loops</li>
</ul>
</section>
</section>
<section id="model-configuration" class="level2">
<h2 class="anchored" data-anchor-id="model-configuration">Model Configuration</h2>
<p>The LM Evaluation Harness supports various model types through a unified interface. Each model type has its own configuration options.</p>
<section id="hugging-face-models" class="level3">
<h3 class="anchored" data-anchor-id="hugging-face-models">Hugging Face Models</h3>
<p>For standard transformers models:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=gpt2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Additional options include:</p>
<ul>
<li><code>dtype</code>: Set precision (e.g., “float16”, “bfloat16”)</li>
<li><code>trust_remote_code</code>: Allow custom model code (set to “true”)</li>
<li><code>use_accelerate</code>: Use the Accelerate library for distributed inference</li>
<li><code>device_map</code>: Control device placement (“auto”, “balanced”, etc.)</li>
</ul>
</section>
<section id="api-based-models" class="level3">
<h3 class="anchored" data-anchor-id="api-based-models">API-Based Models</h3>
<p>For commercial API models:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenAI</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> openai-completions <span class="at">--model_args</span> model=gpt-3.5-turbo-instruct</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Anthropic</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> anthropic <span class="at">--model_args</span> model=claude-2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>API models typically require authentication via environment variables.</p>
</section>
<section id="accelerated-inference" class="level3">
<h3 class="anchored" data-anchor-id="accelerated-inference">Accelerated Inference</h3>
<p>For faster evaluation using vLLM:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> vllm <span class="at">--model_args</span> pretrained=meta-llama/Llama-2-7b-hf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="local-server-models" class="level3">
<h3 class="anchored" data-anchor-id="local-server-models">Local Server Models</h3>
<p>For models hosted on a local server:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> local-completions <span class="at">--model_args</span> base_url=http://localhost:8000/v1/completions</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="task-configuration" class="level2">
<h2 class="anchored" data-anchor-id="task-configuration">Task Configuration</h2>
<p>Tasks in the harness are configured through YAML files, providing a declarative way to define evaluation setups.</p>
<section id="understanding-task-yaml-structure" class="level3">
<h3 class="anchored" data-anchor-id="understanding-task-yaml-structure">Understanding Task YAML Structure</h3>
<p>A basic task configuration includes:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">task</span><span class="kw">:</span><span class="at"> task_name</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_path</span><span class="kw">:</span><span class="at"> huggingface/dataset_name</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_name</span><span class="kw">:</span><span class="at"> subset_name</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">training_split</span><span class="kw">:</span><span class="at"> train</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">validation_split</span><span class="kw">:</span><span class="at"> validation</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">test_split</span><span class="kw">:</span><span class="at"> test</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_text</span><span class="kw">:</span><span class="at"> </span><span class="st">"{{passage}}</span><span class="sc">\n</span><span class="st">Question: {{question}}?</span><span class="sc">\n</span><span class="st">Answer:"</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_target</span><span class="kw">:</span><span class="at"> </span><span class="st">"{{answer}}"</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="fu">metric_list</span><span class="kw">:</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">metric</span><span class="kw">:</span><span class="at"> exact_match</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">aggregation</span><span class="kw">:</span><span class="at"> mean</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">higher_is_better</span><span class="kw">:</span><span class="at"> </span><span class="ch">true</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Key fields include:</p>
<ul>
<li><code>task</code>: Unique identifier for the task</li>
<li><code>dataset_path</code>: Path to the dataset on HuggingFace Hub</li>
<li><code>doc_to_text</code>: Template for input text (using Jinja2)</li>
<li><code>doc_to_target</code>: Template for target output</li>
<li><code>metric_list</code>: Metrics for evaluation</li>
</ul>
</section>
<section id="multiple-choice-tasks" class="level3">
<h3 class="anchored" data-anchor-id="multiple-choice-tasks">Multiple Choice Tasks</h3>
<p>For multiple choice tasks, additional configuration is needed:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">output_type</span><span class="kw">:</span><span class="at"> multiple_choice</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_text</span><span class="kw">:</span><span class="at"> </span><span class="st">"{{question}}</span><span class="sc">\n</span><span class="st">Answer:"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_target</span><span class="kw">:</span><span class="at"> </span><span class="dv">2</span><span class="co">  # Index of correct answer</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_choice</span><span class="kw">:</span><span class="at"> </span><span class="st">"{{[choice1, choice2, choice3, choice4]}}"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="using-filters" class="level3">
<h3 class="anchored" data-anchor-id="using-filters">Using Filters</h3>
<p>Filters allow post-processing of model outputs:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">filter_list</span><span class="kw">:</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> </span><span class="st">"extract-answer"</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">filter</span><span class="kw">:</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="fu">function</span><span class="kw">:</span><span class="at"> </span><span class="st">"regex"</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">regex_pattern</span><span class="kw">:</span><span class="at"> </span><span class="st">"The answer is (</span><span class="sc">\\</span><span class="st">d+)"</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="fu">function</span><span class="kw">:</span><span class="at"> </span><span class="st">"take_first"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="using-local-datasets" class="level3">
<h3 class="anchored" data-anchor-id="using-local-datasets">Using Local Datasets</h3>
<p>To load a local dataset for evaluation, you can specify data files in the <code>dataset_kwargs</code> field:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_path</span><span class="kw">:</span><span class="at"> json</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_name</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_kwargs</span><span class="kw">:</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">data_files</span><span class="kw">:</span><span class="at"> /path/to/my/json</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or with files already split into separate directories:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_path</span><span class="kw">:</span><span class="at"> arrow</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset_kwargs</span><span class="kw">:</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">data_files</span><span class="kw">:</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">train</span><span class="kw">:</span><span class="at"> /path/to/arrow/train/data-00000-of-00001.arrow</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">validation</span><span class="kw">:</span><span class="at"> /path/to/arrow/validation/data-00000-of-00001.arrow</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="advanced-features" class="level2">
<h2 class="anchored" data-anchor-id="advanced-features">Advanced Features</h2>
<section id="chat-templates" class="level3">
<h3 class="anchored" data-anchor-id="chat-templates">Chat Templates</h3>
<p>For evaluating chat models with the appropriate formatting:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=mistralai/Mistral-7B-Instruct-v0.2 <span class="at">--tasks</span> mmlu <span class="at">--num_fewshot</span> 5 <span class="at">--apply_chat_template</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This applies the model’s chat template to the prompt, essential for instruction-tuned models.</p>
<p>For models with multiple chat templates:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--apply_chat_template</span> chatml</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The chat template handling in lm-evaluation-harness has been updated to better support likelihood and multiple-choice based tasks with chat templates. When <code>apply_chat_template</code> is set to <code>True</code>, the target delimiter is now set to an empty string instead of using the configured delimiter.</p>
<p>This prevents interference between chat template formatting and the default delimiter system, which is particularly important for multiple choice tasks where the template itself handles spacing.</p>
</section>
<section id="few-shot-as-multi-turn-conversations" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-as-multi-turn-conversations">Few-Shot as Multi-Turn Conversations</h3>
<p>Format few-shot examples as a conversation history:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--num_fewshot</span> 3 <span class="at">--apply_chat_template</span> <span class="at">--fewshot_as_multiturn</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="task-groups-and-benchmarks" class="level3">
<h3 class="anchored" data-anchor-id="task-groups-and-benchmarks">Task Groups and Benchmarks</h3>
<p>Run multiple related tasks as a benchmark:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=gpt2 <span class="at">--tasks</span> mmlu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This runs all MMLU subtasks and provides both individual and aggregate metrics.</p>
<p>For creating your own group configurations, you can create a group YAML config with a <code>group</code> key which denotes the name of the group and a <code>task</code> key which lists the tasks to include. A good example is in <code>lm_eval/tasks/mmlu/default/_mmlu.yaml</code>.</p>
</section>
<section id="decontamination" class="level3">
<h3 class="anchored" data-anchor-id="decontamination">Decontamination</h3>
<p>Check for training data contamination:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=gpt2 <span class="at">--tasks</span> sciq</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>When enabled on a task, this checks for n-gram overlaps with training data.</p>
<p>The decontamination procedure tests model generalization by detecting whether test set data exists in the training set (contamination). OpenAI defined a test document as contaminated if any N-gram overlap existed with any training document, using N values between 8 and 13 depending on dataset.</p>
</section>
<section id="caching-results" class="level3">
<h3 class="anchored" data-anchor-id="caching-results">Caching Results</h3>
<p>Cache evaluated results to speed up repeated runs:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--use_cache</span> /path/to/cache <span class="at">--cache_requests</span> true</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="creating-custom-tasks" class="level2">
<h2 class="anchored" data-anchor-id="creating-custom-tasks">Creating Custom Tasks</h2>
<section id="task-file-structure" class="level3">
<h3 class="anchored" data-anchor-id="task-file-structure">Task File Structure</h3>
<p>To create a new task:</p>
<ol type="1">
<li>Create a YAML file in <code>lm_eval/tasks/your_task_name.yaml</code></li>
<li>Configure dataset parameters, prompt templates, and metrics</li>
<li>Register the task with a unique name</li>
</ol>
<p>For complex preprocessing, you can add Python functions:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">process_docs</span><span class="kw">:</span><span class="at"> !function utils.process_docs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With a corresponding Python file:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># utils.py</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_docs(dataset):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _process_doc(doc):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess document</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> processed_doc</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dataset.<span class="bu">map</span>(_process_doc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="writing-prompt-templates" class="level3">
<h3 class="anchored" data-anchor-id="writing-prompt-templates">Writing Prompt Templates</h3>
<p>When creating prompts, users will use <code>doc_to_text</code>, <code>doc_to_target</code>, and <code>doc_to_choice</code> (optional). <code>doc_to_text</code> defines the input string a model will be given while <code>doc_to_target</code> and <code>doc_to_choice</code> will be used to generate the target text.</p>
<p><code>doc_to_target</code> can be either a text string that refers to the target string or an integer that refers to the index of the correct label. When it is set as an index, <code>doc_to_choice</code> must also be set with the appropriate list of possible choice strings.</p>
<p>For simple cases, you can enter the feature name directly:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_text</span><span class="kw">:</span><span class="at"> startphrase</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_target</span><span class="kw">:</span><span class="at"> label</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The evaluation harness supports the <a href="https://jinja.palletsprojects.com/en/3.1.x/">Jinja 2</a> templating language for writing prompts. For example:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">doc_to_text</span><span class="kw">:</span><span class="at"> </span><span class="st">"{{passage}}</span><span class="sc">\n</span><span class="st">Question: {{question}}?</span><span class="sc">\n</span><span class="st">Answer:"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Such that <code>{passage}</code> will be replaced by <code>doc["passage"]</code> and <code>{question}</code> with <code>doc["question"]</code> when rendering the prompt template.</p>
</section>
<section id="importing-prompts-from-promptsource" class="level3">
<h3 class="anchored" data-anchor-id="importing-prompts-from-promptsource">Importing Prompts from Promptsource</h3>
<p>You can load prompts from Promptsource by using the <code>use_prompt</code> argument:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">use_prompt</span><span class="kw">:</span><span class="at"> </span><span class="st">"promptsource:GPT-3 Style"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If you would like to run evaluation on all prompt templates:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">use_prompt</span><span class="kw">:</span><span class="at"> </span><span class="st">"promptsource:*"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="creating-task-filters" class="level3">
<h3 class="anchored" data-anchor-id="creating-task-filters">Creating Task Filters</h3>
<p>Filters allow you to post-process model outputs before scoring them. A full list of supported filter operations can be found in <code>lm_eval/filters/__init__.py</code>. Contributions of new filter types are welcome!</p>
<p>Multiple filter pipelines can run on the same model outputs generated in one run on a task. This enables scenarios like:</p>
<ol type="1">
<li>Post-processing output text by truncating or extracting answers</li>
<li>Ensembling over multiple “takes” on a document</li>
</ol>
<p>For example, in the file <code>lm_eval/tasks/gsm8k/gsm8k-cot-self-consistency.yaml</code>, the implementation emulates the setup used by <a href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Prompting</a>, which generates multiple chain-of-thought outputs, extracts numeric answers, and uses majority voting.</p>
</section>
</section>
<section id="best-practices-and-common-pitfalls" class="level2">
<h2 class="anchored" data-anchor-id="best-practices-and-common-pitfalls">Best Practices and Common Pitfalls</h2>
<ol type="1">
<li><strong>Tokenization Alignment</strong>
<ul>
<li>Verify model logits align with target token positions</li>
<li>Prevent off-by-one errors in likelihood calculation</li>
<li>Use reference implementations from <code>HFLM</code> as guides</li>
</ul></li>
<li><strong>Template Safety</strong>
<ul>
<li>Escape special characters in Jinja templates</li>
<li>Validate few-shot example field consistency</li>
<li>Implement template versioning through <code>tokenizer_name</code></li>
</ul></li>
<li><strong>Performance Considerations</strong>
<ul>
<li>Implement request reordering for large evaluations</li>
<li>Utilize batch processing where supported</li>
<li>Profile memory usage during generation tasks</li>
</ul></li>
<li><strong>Evaluation Validity</strong>
<ul>
<li>Separate few-shot and test splits</li>
<li>Audit metric implementations for task appropriateness</li>
<li>Verify chat template application through debug output</li>
</ul></li>
<li><strong>Resource Management</strong>
<ul>
<li>Use <code>--batch_size auto</code> to automatically determine optimal batch size</li>
<li>For API models, set appropriate <code>num_concurrent</code> and timeout values</li>
<li>Consider using <code>--limit</code> for debugging to evaluate only a subset of documents</li>
</ul></li>
</ol>
</section>
<section id="adding-new-models-to-the-framework" class="level2">
<h2 class="anchored" data-anchor-id="adding-new-models-to-the-framework">Adding New Models to the Framework</h2>
<p>When implementing a new model type, all models must subclass the <code>lm_eval.api.model.LM</code> class, which enforces a common interface:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyCustomLM(LM):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> loglikelihood(<span class="va">self</span>, requests: <span class="bu">list</span>[Instance]) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">float</span>, <span class="bu">bool</span>]]:</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation for calculating conditional log probabilities</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> loglikelihood_rolling(<span class="va">self</span>, requests: <span class="bu">list</span>[Instance]) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">float</span>, <span class="bu">bool</span>]]:</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation for calculating full-text log probabilities</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_until(<span class="va">self</span>, requests: <span class="bu">list</span>[Instance]) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">str</span>]:</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation for free-form text generation</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>These methods support three types of requests:</p>
<ul>
<li><code>generate_until</code>: Generates text from the model until reaching stopping criteria</li>
<li><code>loglikelihood</code>: Calculates log probability of a target string given an input</li>
<li><code>loglikelihood_rolling</code>: Calculates log probability of an entire input string</li>
</ul>
<p>To make your model usable via CLI, use the <code>lm_eval.api.registry.register_model</code> decorator:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lm_eval.api.registry <span class="im">import</span> register_model</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="at">@register_model</span>(<span class="st">"&lt;name1&gt;"</span>, <span class="st">"&lt;name2&gt;"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyCustomLM(LM):</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implementation</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For adding chat templates, implement three additional methods:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyCustomLM(LM):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> tokenizer_name(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Return the name of the model's tokenizer and/or chat template."""</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> chat_template(<span class="va">self</span>, chat_template: Union[<span class="bu">bool</span>, <span class="bu">str</span>] <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get the appropriate chat template string."""</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> apply_chat_template(<span class="va">self</span>, chat_history: List[Dict[<span class="bu">str</span>, <span class="bu">str</span>]]) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Process a chat history into a string for the model."""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="practical-examples" class="level2">
<h2 class="anchored" data-anchor-id="practical-examples">Practical Examples</h2>
<section id="evaluating-a-local-hugging-face-model" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-a-local-hugging-face-model">Evaluating a Local Hugging Face Model</h3>
<div class="sourceCode" id="cb33"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="dt">\</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">--model_args</span> pretrained=mistralai/Mistral-7B-Instruct-v0.2,device_map=auto,trust_remote_code=true <span class="dt">\</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">--tasks</span> mmlu,hellaswag <span class="dt">\</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">--num_fewshot</span> 5 <span class="dt">\</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">--batch_size</span> auto <span class="dt">\</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">--output_path</span> results/mistral-7b.json <span class="dt">\</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">--apply_chat_template</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="evaluating-a-quantized-model" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-a-quantized-model">Evaluating a Quantized Model</h3>
<div class="sourceCode" id="cb34"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="dt">\</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">--model_args</span> pretrained=TheBloke/Llama-2-13B-GPTQ,gptq=true <span class="dt">\</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">--tasks</span> gsm8k <span class="dt">\</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">--num_fewshot</span> 5 <span class="dt">\</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">--batch_size</span> 1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="evaluating-an-api-model" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-an-api-model">Evaluating an API Model</h3>
<div class="sourceCode" id="cb35"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set OPENAI_API_KEY environment variable first</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> openai-chat <span class="dt">\</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">--model_args</span> model=gpt-4-turbo <span class="dt">\</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">--tasks</span> mmlu,bbh <span class="dt">\</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">--num_fewshot</span> 5 <span class="dt">\</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">--batch_size</span> 10</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="self-consistency-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="self-consistency-evaluation">Self-Consistency Evaluation</h3>
<div class="sourceCode" id="cb36"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm-eval</span> <span class="at">--model</span> hf <span class="dt">\</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">--model_args</span> pretrained=meta-llama/Llama-2-70b-hf <span class="dt">\</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">--tasks</span> gsm8k-cot-self-consistency <span class="dt">\</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">--num_fewshot</span> 8 <span class="dt">\</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">--batch_size</span> 4 <span class="dt">\</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">--gen_kwargs</span> temperature=0.7,top_p=0.95</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="working-with-vision-language-models" class="level3">
<h3 class="anchored" data-anchor-id="working-with-vision-language-models">Working with Vision-Language Models</h3>
<p>The framework also supports multimodal evaluation with the <code>HFMultimodalLM</code> class for models like Llava and Idefics:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lm_eval.models.hf_vlms <span class="im">import</span> HFMultimodalLM</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the model</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> HFMultimodalLM(</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    pretrained<span class="op">=</span><span class="st">"llava-hf/llava-1.5-7b-hf"</span>,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate responses for multimodal inputs</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.generate_until(...)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="contributing-to-lm-evaluation-harness" class="level2">
<h2 class="anchored" data-anchor-id="contributing-to-lm-evaluation-harness">Contributing to lm-evaluation-harness</h2>
<p>EleutherAI welcomes contributions to improve the framework. The project follows these priorities for addressing concerns about prompting and evaluation details:</p>
<ol type="1">
<li>Use procedures with widespread agreement among LLM trainers</li>
<li>Follow clear and unambiguous official implementations</li>
<li>Use procedures with widespread agreement among LLM evaluators</li>
<li>Choose from common implementations when there’s no universal agreement, preferring those found in LLM training papers</li>
</ol>
<p>They maintain an active <a href="https://discord.gg/eleutherai">Discord server</a> with the <code>#lm-thunderdome</code> channel dedicated to developing this project and <code>#release-discussion</code> for support.</p>
<p>Important resources include: - Documentation pages in the <a href="https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs">docs directory</a> - <a href="https://github.com/EleutherAI/lm-evaluation-harness/milestones">GitHub Milestones</a> for tracking progress toward version releases - <a href="https://github.com/orgs/EleutherAI/projects/25">Project Board</a> for tracking work items and feature requests - Discord discussions in the #lm-thunderdome channel</p>
<section id="contributing-a-new-task" class="level3">
<h3 class="anchored" data-anchor-id="contributing-a-new-task">Contributing a New Task</h3>
<p>To contribute a new task:</p>
<ol type="1">
<li>Fork the repository</li>
<li>Create a YAML configuration file</li>
<li>Verify against reference implementations</li>
<li>Add documentation and test results</li>
<li>Submit a pull request</li>
</ol>
<p>For first-time contributors, the team maintains a list of good first issues, which can be found <a href="https://github.com/orgs/EleutherAI/projects/25/views/8">on the project board</a> or by <a href="https://github.com/EleutherAI/lm-evaluation-harness/issues?q=is%3Aopen+label%3A%22good+first+issue%22+label%3A%22help+wanted%22">filtering GitHub Issues</a>.</p>
</section>
<section id="contributing-a-new-model-type" class="level3">
<h3 class="anchored" data-anchor-id="contributing-a-new-model-type">Contributing a New Model Type</h3>
<p>To add support for a new model type:</p>
<ol type="1">
<li>Implement a subclass of <code>lm_eval.api.model.LM</code></li>
<li>Register your model with <code>@register_model</code></li>
<li>Implement the required interface methods</li>
<li>Add documentation and tests</li>
<li>Submit a pull request</li>
</ol>
<p>Code style guidelines:</p>
<ul>
<li>LM Evaluation Harness uses <a href="https://github.com/astral-sh/ruff">ruff</a> for linting via <a href="https://pre-commit.com/">pre-commit</a></li>
<li>Install dev tools via <code>pip install lm_eval[dev]</code> or <code>pip install -e ".[dev]"</code></li>
<li>Run <code>pre-commit install</code> to ensure linters and checks will run upon committing</li>
</ul>
</section>
<section id="improved-documentation-with-mkdocs" class="level3">
<h3 class="anchored" data-anchor-id="improved-documentation-with-mkdocs">Improved Documentation with MkDocs</h3>
<p>I’ve recently contributed to the lm-evaluation-harness project by adding MkDocs support to enhance the documentation experience. This improvement provides a more navigable and user-friendly documentation interface with automatic navigation, search functionality, and better organization of the existing documentation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/3rYxyqm.png" class="img-fluid figure-img"></p>
<figcaption>Pull Request for adding MkDocs to EleutherAI’s lm-evaluation-harness</figcaption>
</figure>
</div>
<p>You can see a preview of the MkDocs implementation at <a href="https://slyracoon23.github.io/lm-evaluation-harness/">my fork’s documentation site</a>. The pull request is currently open and will hopefully be merged into the main repository soon, making the documentation more accessible to new users and contributors.</p>
<p>The MkDocs integration preserves all the existing documentation while providing:</p>
<ul>
<li>Modern, responsive documentation UI</li>
<li>Automatic navigation sidebar</li>
<li>Full-text search capabilities</li>
<li>Improved readability on mobile devices</li>
<li>Better organization of the existing documentation files</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>EleutherAI’s evaluation framework provides a standardized way to assess language model capabilities across a wide range of tasks. By separating the evaluation logic from model implementation, it enables fair comparison between different models and architectures. The declarative configuration system makes it easy to add new tasks and benchmarks, contributing to the growing ecosystem of LLM evaluation.</p>
<p>Whether you’re developing a new model or researching evaluation methodologies, understanding these evaluation methods is crucial for rigorous assessment of language model capabilities.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness">EleutherAI lm-evaluation-harness GitHub Repository</a></li>
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/task_guide.md">Official Task Guide</a></li>
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md">New Task Guide</a></li>
<li><a href="https://wandb.ai/wandb_gen/llm-evaluation/reports/Evaluating-Large-Language-Models-LLMs-with-Eleuther-AI--VmlldzoyOTI0MDQ3">Weights &amp; Biases: Evaluating LLMs with EleutherAI</a></li>
<li><a href="https://mozilla-ai.github.io/lm-buddy/evaluation_concepts.html">Mozilla AI: LM Buddy Evaluation Concepts</a></li>
<li><a href="https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html/monitoring_data_science_models/evaluating-large-language-models_monitor">Red Hat: Evaluating Large Language Models</a></li>
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/API_guide.md">API Guide Documentation</a></li>
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md">Interface Documentation</a></li>
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/model_guide.md">Model Guide Documentation</a></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/slyracoon23\.github\.io\/blog");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "Slyracoon23/blog";
    script.dataset.repoId = "R_kgDOOD0L5w";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOOD0L584CopEq";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "bottom";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><i class="fa-regular fa-copyright" aria-label="copyright"></i> Copyright 2025, Earl Potters</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>