<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Earl Potters">
<meta name="dcterms.date" content="2025-03-18">

<title>Exploring Gemma 3 Model – Earl Potters</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="..//images/favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-46f4cc9626f044588a66931b604fc9c8.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-86ca98530662af5ddd08d363d7d219b9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-4DWYJM47PC"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-4DWYJM47PC', { 'anonymize_ip': true});
</script>
<script src="../assets/citations.js"></script>
<script>
    !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey canRenderSurveyAsync identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
    posthog.init('phc_3LFGZh7SWQGVrh5GwvDO3qwdESpdJb9AnpJHks39zdA', {
        api_host: 'https://us.i.posthog.com',
        person_profiles: 'always',
    })
</script>


<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="../assets/citations.css">
<meta property="og:title" content="Exploring Gemma 3 Model – Earl Potters">
<meta property="og:description" content="A deep dive into Google’s latest open source language model">
<meta property="og:image" content="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b.width-1200.format-webp.webp">
<meta property="og:site_name" content="Earl Potters">
<meta name="twitter:title" content="Exploring Gemma 3 Model – Earl Potters">
<meta name="twitter:description" content="A deep dive into Google’s latest open source language model">
<meta name="twitter:image" content="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b.width-1200.format-webp.webp">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Earl Potters</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text"><i class="fa-solid fa-address-card" aria-label="address-card"></i> About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../posts.html"> 
<span class="menu-text"><i class="fa-solid fa-newspaper" aria-label="newspaper"></i> Posts</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/SRacoon23"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/earl-potters-b2b306187/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Slyracoon23"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://huggingface.co/Slyracoon23"> 
<span class="menu-text"><img src="https://mlabonne.github.io/blog/images/hf-icon.svg" class="img-fluid"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../posts/2025-03-15_what_is_prompt_engineering.html">🗣️ <strong>Large Language Models</strong></a></li><li class="breadcrumb-item"><a href="../posts/2025-03-18_exploring_gemma_3_model.html">Exploring Gemma 3 Model</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../posts/2025-03-15_what_is_prompt_engineering.html">🗣️ <strong>Large Language Models</strong></a></li><li class="breadcrumb-item"><a href="../posts/2025-03-18_exploring_gemma_3_model.html">Exploring Gemma 3 Model</a></li></ol></nav>
      <h1 class="title">Exploring Gemma 3 Model</h1>
            <p class="subtitle lead">A deep dive into Google’s latest open source language model</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Large Language Models</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Earl Potters </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 18, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">🤖 <strong>AI Agents</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-06-06_ai_engineer_worlds_fair.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Engineer World’s Fair</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">🗣️ <strong>Large Language Models</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-15_what_is_prompt_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is Prompt Engineering?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-16_what_are_image_embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What are Image Embeddings?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-18_exploring_gemma_3_model.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Exploring Gemma 3 Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-21_eleutherai-evaluation-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EleutherAI’s lm-evaluation-harness</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-04-05_model_context_protocol_tool_poisoning_attacks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Context Protocol Tool Poisoning Attacks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-04-27_gemini-image-segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gemini Image Segmentation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-05-04_game_of_ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A Game of Ethics: Quantifying AI Moral Reasoning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">🌐 <strong>Web Technologies</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-14_what_is_rrweb.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is rrweb?</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">🗄️ <strong>Databases</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-04-19_sql_query_performance_postgres.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Measure SQL Query Performance on Postgres</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">📝 <strong>Writing &amp; Content</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/2025-03-24_how_to_stop_being_accused_of_ai_slop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Stop Being Accused of AI Slop</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title"><strong>Sections</strong></h2>
   
  <ul class="collapse">
  <li><a href="#the-gemma-3-family-an-overview" id="toc-the-gemma-3-family-an-overview" class="nav-link active" data-scroll-target="#the-gemma-3-family-an-overview">The Gemma 3 Family: An Overview</a></li>
  <li><a href="#technical-architecture-and-innovations" id="toc-technical-architecture-and-innovations" class="nav-link" data-scroll-target="#technical-architecture-and-innovations">Technical Architecture and Innovations</a></li>
  <li><a href="#capabilities-and-features" id="toc-capabilities-and-features" class="nav-link" data-scroll-target="#capabilities-and-features">Capabilities and Features</a></li>
  <li><a href="#shieldgemma-2-enhanced-safety-features" id="toc-shieldgemma-2-enhanced-safety-features" class="nav-link" data-scroll-target="#shieldgemma-2-enhanced-safety-features">ShieldGemma 2: Enhanced Safety Features</a></li>
  <li><a href="#performance-and-benchmarks" id="toc-performance-and-benchmarks" class="nav-link" data-scroll-target="#performance-and-benchmarks">Performance and Benchmarks</a></li>
  <li><a href="#practical-applications-and-use-cases" id="toc-practical-applications-and-use-cases" class="nav-link" data-scroll-target="#practical-applications-and-use-cases">Practical Applications and Use Cases</a></li>
  <li><a href="#getting-started-and-hands-on-with-gemma-3" id="toc-getting-started-and-hands-on-with-gemma-3" class="nav-link" data-scroll-target="#getting-started-and-hands-on-with-gemma-3">Getting Started and Hands-On with Gemma 3</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#appendix-reproducing-the-benchmark-results" id="toc-appendix-reproducing-the-benchmark-results" class="nav-link" data-scroll-target="#appendix-reproducing-the-benchmark-results">Appendix: Reproducing the Benchmark Results</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b.width-1200.format-webp.webp" class="img-fluid figure-img"></p>
<figcaption>Gemma 3 Model</figcaption>
</figure>
</div>
<p>Google’s newest AI model family, <strong>Gemma 3</strong>, represents a significant advancement in accessible artificial intelligence. Released on March 12, 2025, this collection of <em>lightweight yet powerful</em> models has been designed to deliver impressive capabilities while running efficiently on a single GPU or TPU. Building upon the success of previous Gemma models, which have seen over <strong>100 million downloads</strong> and inspired <strong>60,000+ community variations</strong>, Gemma 3 brings multimodality, enhanced language support, and improved reasoning to Google’s open model ecosystem according to <a href="https://developers.googleblog.com/en/introducing-gemma3/">Google’s developer blog</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Innovations in Gemma 3
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Multimodal capabilities</strong> in all models except the 1B variant</li>
<li><strong>Extended context windows</strong> of up to 128K tokens</li>
<li><strong>Support for 140+ languages</strong> in the larger models</li>
<li><strong>Significantly improved efficiency-to-performance ratio</strong></li>
</ul>
</div>
</div>
<section id="the-gemma-3-family-an-overview" class="level2">
<h2 class="anchored" data-anchor-id="the-gemma-3-family-an-overview">The Gemma 3 Family: An Overview</h2>
<p>Gemma 3 comes in four different parameter sizes to accommodate various hardware setups and performance needs: 1 billion, 4 billion, 12 billion, and 27 billion parameters as detailed on <a href="https://blog.google/technology/developers/gemma-3/">Google’s Blog</a> and <a href="https://huggingface.co/blog/gemma3">Hugging Face</a>. These models are built from the same research and technology that powers Google’s flagship Gemini 2.0 models but optimized for more efficient operation. Each size is available in both <em>pre-trained versions</em> (which can be fine-tuned for specific domains) and <em>general-purpose instruction-tuned variants</em>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 38%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Model Size</th>
<th>Specifications</th>
<th>Capabilities</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Gemma 3 1B</strong></td>
<td>• 1 Billion parameters<br>• 32K token context<br>• Trained on 2 trillion tokens</td>
<td>• Text only (no images)<br>• English language only<br>• Optimized for low-resource devices<br>• Ideal for simple on-device applications</td>
</tr>
<tr class="even">
<td><strong>Gemma 3 4B</strong></td>
<td>• 4 Billion parameters<br>• 128K token context<br>• Trained on 4 trillion tokens</td>
<td>• Multimodal (images and text)<br>• 140+ languages supported<br>• Good balance of performance and efficiency<br>• Supports function calling</td>
</tr>
<tr class="odd">
<td><strong>Gemma 3 12B</strong></td>
<td>• 12 Billion parameters<br>• 128K token context<br>• Trained on 12 trillion tokens</td>
<td>• Multimodal (images and text)<br>• 140+ languages supported<br>• Enhanced reasoning capabilities<br>• Can process ~30 high-res images or 300-page book</td>
</tr>
<tr class="even">
<td><strong>Gemma 3 27B</strong></td>
<td>• 27 Billion parameters<br>• 128K token context<br>• Trained on 14 trillion tokens</td>
<td>• Multimodal (images and text)<br>• 140+ languages supported<br>• Highest performance in the family<br>• LMSys Elo score of 1339</td>
</tr>
</tbody>
</table>
<p>What makes Gemma 3 particularly noteworthy is its ability to deliver <strong>near state-of-the-art performance</strong> while requiring <em>significantly fewer computational resources</em> than competitors. Google claims Gemma 3 achieves <strong>98% of DeepSeek’s R1 accuracy</strong> (with Elo scores of 1338 versus 1363) while using only <strong>one NVIDIA H100 GPU</strong> compared to R1’s estimated requirement of 32 GPUs, according to <a href="https://www.zdnet.com/article/google-claims-gemma-3-reaches-98-of-deepseeks-accuracy-using-only-one-gpu/">ZDNet’s report</a>.</p>
</section>
<section id="technical-architecture-and-innovations" class="level2">
<h2 class="anchored" data-anchor-id="technical-architecture-and-innovations">Technical Architecture and Innovations</h2>
<p>Gemma 3’s impressive efficiency-to-performance ratio stems from several architectural innovations. The model employs sophisticated attention mechanisms that go beyond traditional <em>Rotary Position Embedding (RoPE)</em> technology as explained by <a href="https://www.perplexity.ai/page/google-unveils-gemma-3-ai-mode-.cGGCsMoSo2X_pTrtcBw_Q">Perplexity AI</a>. To achieve its extended context length, Google first pretrained the models with 32k token sequences, then scaled the 4B, 12B, and 27B variants to handle 128k tokens at the end of pretraining, saving significant computational resources.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Technical Breakthrough
</div>
</div>
<div class="callout-body-container callout-body">
<p>The positional embeddings were significantly upgraded, with the RoPE base frequency increased from 10k in Gemma 2 to <strong>1 million</strong> in Gemma 3, and scaled by a factor of 8 to accommodate longer contexts.</p>
</div>
</div>
<p>KV cache management was optimized using a <em>sliding window interleaved attention approach</em>, with the ratio of local to global layers adjusted from 1:1 to 5:1 and the window size reduced to 1024 tokens (down from 4096).</p>
<p>Training data volume scaled with model size: <strong>2 trillion tokens</strong> for the 1B model, <strong>4 trillion</strong> for 4B, <strong>12 trillion</strong> for 12B, and <strong>14 trillion tokens</strong> for the 27B model, all processed using Google TPUs with the JAX framework. A key technique enabling Gemma 3’s efficiency is <em>distillation</em>, whereby trained weights from larger models are extracted and transferred to the smaller Gemma 3 models, as described by <a href="https://developers.googleblog.com/en/introducing-gemma3/">Google’s developers</a>.</p>
</section>
<section id="capabilities-and-features" class="level2">
<h2 class="anchored" data-anchor-id="capabilities-and-features">Capabilities and Features</h2>
<p>Gemma 3 introduces several impressive capabilities:</p>
<section id="multimodal-processing" class="level3">
<h3 class="anchored" data-anchor-id="multimodal-processing">Multimodal Processing</h3>
<p>All models except the 1B variant can process both images and text, enabling applications that analyze visual content alongside textual data. The models can handle <strong>text, images, and even short videos</strong>, making them versatile tools for content analysis as noted on <a href="https://blog.google/technology/developers/gemma-3/">Google’s Blog</a> and <a href="https://www.perplexity.ai/page/google-unveils-gemma-3-ai-mode-.cGGCsMoSo2X_pTrtcBw_Q">Perplexity AI</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Processing Approach
</div>
</div>
<div class="callout-body-container callout-body">
<p>While Gemma 3 can process videos, it’s worth noting that its video understanding works by processing linearly spaced image frames sampled from the video. The model typically samples a fixed number of frames at regular intervals throughout the video, then analyzes these frames using its vision capabilities and integrates information across them to understand temporal relationships. This approach allows Gemma 3 to handle video content without requiring specialized video-specific architecture components.</p>
</div>
</div>
</section>
<section id="extensive-language-support" class="level3">
<h3 class="anchored" data-anchor-id="extensive-language-support">Extensive Language Support</h3>
<p>The 4B, 12B, and 27B models support over <strong>140+ languages</strong>, while the 1B model focuses on English only. This multilingual capability makes Gemma 3 suitable for global applications and diverse user bases.</p>
</section>
<section id="long-context-windows" class="level3">
<h3 class="anchored" data-anchor-id="long-context-windows">Long Context Windows</h3>
<p>Gemma 3 offers expanded context windows: 32k tokens for the 1B model and <strong>128k tokens</strong> for the larger variants. This allows the models to process approximately <em>30 high-resolution images</em>, a <em>300-page book</em>, or over an <em>hour of video</em> in a single context window.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Performance Impact
</div>
</div>
<div class="callout-body-container callout-body">
<p>The extended context window is not just a numeric improvement—it fundamentally changes what these models can process in a single pass, enabling entirely new use cases that weren’t possible with previous models.</p>
</div>
</div>
</section>
<section id="advanced-functionality" class="level3">
<h3 class="anchored" data-anchor-id="advanced-functionality">Advanced Functionality</h3>
<p>The models support <em>function calling</em> and <em>structured output</em>, enabling task automation and the creation of agentic experiences. Their reasoning capabilities have been enhanced for better performance in math, coding, and instruction following as detailed by <a href="https://developers.googleblog.com/en/introducing-gemma3/">Google’s developers</a>.</p>
</section>
</section>
<section id="shieldgemma-2-enhanced-safety-features" class="level2">
<h2 class="anchored" data-anchor-id="shieldgemma-2-enhanced-safety-features">ShieldGemma 2: Enhanced Safety Features</h2>
<p>Alongside Gemma 3, Google has also released <strong>ShieldGemma 2</strong>, an enhanced version of the model that includes additional safety features and guardrails. ShieldGemma 2 is specifically designed to address concerns around potentially harmful outputs while maintaining the impressive capabilities of the base models.</p>
<p>ShieldGemma 2 builds upon Google’s <em>responsible AI principles</em> and incorporates advanced techniques to: - Filter out harmful content - Detect and refuse problematic requests - Ensure outputs adhere to safety guidelines</p>
<p>This makes it particularly suitable for customer-facing applications and environments where content safety is paramount.</p>
<p>Like the main Gemma 3 models, ShieldGemma 2 is available through Google’s AI platforms and can be accessed via the same channels as the standard models. Developers concerned with the safety aspects of AI deployment should consider ShieldGemma 2 as their starting point.</p>
</section>
<section id="performance-and-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="performance-and-benchmarks">Performance and Benchmarks</h2>
<p>Gemma 3’s 27B instruction-tuned model achieves an impressive LMSys Elo score of 1339, placing it among the <strong>top 10 best models</strong>, including leading closed ones according to <a href="https://huggingface.co/blog/gemma3">Hugging Face</a> and <a href="https://www.zdnet.com/article/google-claims-gemma-3-reaches-98-of-deepseeks-accuracy-using-only-one-gpu/">ZDNet</a>. This score is comparable to OpenAI’s o1-preview and surpasses other non-thinking open models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/gemma3/chatbot-arena.png" class="img-fluid figure-img"></p>
<figcaption>Gemma 3 27B IT achieves a competitive Elo score of 1338 in the Chatbot Arena rankings</figcaption>
</figure>
</div>
<p>In specific benchmarks, the 27B model shows strong performance across various tasks:</p>
<ul>
<li><strong>MMLU-Pro</strong>: 67.5</li>
<li><strong>LiveCodeBench</strong>: 29.7</li>
<li><strong>Bird-SQL</strong>: 54.4</li>
<li><strong>GPQA Diamond</strong>: 42.4</li>
<li><strong>MATH</strong>: 69.0</li>
<li><strong>FACTS Grounding</strong>: 74.9</li>
<li><strong>MMMU</strong>: 64.9</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Benchmark Significance
</div>
</div>
<div class="callout-body-container callout-body">
<p>The strong performance on MMLU-Pro (67.5) and MATH (69.0) is particularly significant as these benchmarks test advanced reasoning capabilities across multiple domains, showing Gemma 3’s strength in handling complex, knowledge-intensive tasks.</p>
</div>
</div>
<p>The model outperforms <strong>Llama-405B</strong>, <strong>DeepSeek-V3</strong>, and OpenAI’s <strong>o3-mini</strong> in preliminary human preference evaluations on LMArena’s leaderboard. Notably, Gemma 3 27B instruction-tuned model even beats <strong>Gemini 1.5-Pro</strong> across several benchmarks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/gemma3/pefr-it.png" class="img-fluid figure-img"></p>
<figcaption>Performance comparison of Gemma 3 instruction-tuned models across various benchmarks, showing how Gemma-3-4B-IT outperforms Gemma-2-27B-IT and Gemma-3-27B-IT beats Gemini 1.5-Pro on several metrics</figcaption>
</figure>
</div>
</section>
<section id="practical-applications-and-use-cases" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications-and-use-cases">Practical Applications and Use Cases</h2>
<p>Gemma 3’s combination of efficiency and capability makes it particularly well-suited for a variety of practical applications:</p>
<section id="personal-code-assistant" class="level3">
<h3 class="anchored" data-anchor-id="personal-code-assistant">Personal Code Assistant</h3>
<p>Gemma 3’s improved reasoning and coding capabilities make it an excellent <em>personal code assistant</em>. Developers can use it to generate code, debug existing implementations, and explain complex programming concepts. The model’s ability to understand context and provide structured outputs enhances its utility in development environments.</p>
</section>
<section id="business-email-assistant" class="level3">
<h3 class="anchored" data-anchor-id="business-email-assistant">Business Email Assistant</h3>
<p>With support for over 140+ languages and advanced language understanding, Gemma 3 can serve as a sophisticated <em>email assistant</em> that helps draft responses, summarize long email threads, and even translate communications for international teams.</p>
</section>
<section id="multimodal-content-analysis" class="level3">
<h3 class="anchored" data-anchor-id="multimodal-content-analysis">Multimodal Content Analysis</h3>
<p>The 4B, 12B, and 27B models’ ability to process both text and images enable applications that can analyze visual content alongside textual data. This is particularly useful for <strong>content moderation</strong>, <strong>media analysis</strong>, and creating <strong>accessible technology</strong> for visually impaired users.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Real-World Example
</div>
</div>
<div class="callout-body-container callout-body">
<p>A content moderation system powered by Gemma 3 could analyze both the text and images in social media posts to identify potentially harmful content with greater accuracy than text-only models, helping platforms maintain safer environments for users.</p>
</div>
</div>
</section>
<section id="on-device-ai-applications" class="level3">
<h3 class="anchored" data-anchor-id="on-device-ai-applications">On-Device AI Applications</h3>
<p>Gemma 3’s efficiency makes it suitable for <em>on-device deployment</em>, enabling AI capabilities even in environments with limited connectivity. This opens possibilities for mobile applications, edge computing scenarios, and privacy-preserving implementations where data doesn’t need to leave the user’s device.</p>
</section>
<section id="chatbots-and-conversational-agents" class="level3">
<h3 class="anchored" data-anchor-id="chatbots-and-conversational-agents">Chatbots and Conversational Agents</h3>
<p>The improved reasoning and instruction-following capabilities make Gemma 3 an excellent foundation for building sophisticated chatbots and conversational agents that can maintain context over long interactions and handle complex queries.</p>
</section>
</section>
<section id="getting-started-and-hands-on-with-gemma-3" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-and-hands-on-with-gemma-3">Getting Started and Hands-On with Gemma 3</h2>
<p>Now that we’ve explored Gemma 3’s capabilities and architecture, let’s dive into how you can start using it for your own projects and evaluate its performance through benchmarking.</p>
<section id="official-resources-and-access-options" class="level3">
<h3 class="anchored" data-anchor-id="official-resources-and-access-options">Official Resources and Access Options</h3>
<p>Google provides several ways to access and work with Gemma 3:</p>
<ul>
<li><a href="https://blog.google/technology/developers/gemma-3/">Google’s Gemma 3 Announcement</a> - Official announcement with overview of capabilities</li>
<li><a href="https://developers.googleblog.com/en/introducing-gemma3/">Google Developers Blog: Introducing Gemma 3</a> - Technical details and developer guide</li>
<li><a href="https://ai.google.dev/gemma/docs/core">Gemma Documentation</a> - Comprehensive documentation and guides</li>
</ul>
<p>You can quickly get started with Gemma 3 through several channels:</p>
<ul>
<li><strong>Instant exploration:</strong> Try Gemma 3 at full precision directly in your browser with <a href="https://ai.google.dev/">Google AI Studio</a> - <em>no setup needed</em></li>
<li><strong>Download the models:</strong> Get the model weights from <a href="https://huggingface.co/collections/google/gemma-3-665e8b35aa3b68c5b4195b15">Hugging Face</a>, <a href="https://ollama.com/">Ollama</a>, or <a href="https://www.kaggle.com/">Kaggle</a></li>
<li><strong>Deploy at scale:</strong> Bring your custom Gemma 3 creations to market with <a href="https://cloud.google.com/vertex-ai">Vertex AI</a> or run inference on Cloud Run with Ollama</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Getting the Best Performance
</div>
</div>
<div class="callout-body-container callout-body">
<p>For optimal results, run Gemma 3 models with bfloat16 precision. Quality may degrade when using lower precision formats, particularly for the larger models.</p>
</div>
</div>
</section>
<section id="development-and-deployment-options" class="level3">
<h3 class="anchored" data-anchor-id="development-and-deployment-options">Development and Deployment Options</h3>
<p>Gemma 3 can be integrated into your workflow in several ways:</p>
<ul>
<li><strong>Web applications:</strong> Use Google AI Edge to bring Gemma 3 capabilities to web applications</li>
<li><strong>Mobile integration:</strong> Implement Gemma 3 on mobile devices with Google AI Edge for Android</li>
<li><strong>Enterprise deployment:</strong> Utilize Google Cloud’s infrastructure for large-scale implementations</li>
<li><strong>Local development:</strong> Work with Gemma 3 using familiar tools including <em>Hugging Face Transformers</em>, <em>JAX</em>, <em>MaxText</em>, <em>Gemma.cpp</em>, <em>llama.cpp</em>, and <em>Unsloth</em></li>
</ul>
<p>The model offers <strong>quantized versions</strong> for faster performance and reduced computational requirements, making it accessible even on consumer-grade hardware. With multiple deployment options, Gemma 3 gives you the flexibility to choose the best fit for your specific use case.</p>
</section>
<section id="setting-up-a-local-evaluation-environment" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-a-local-evaluation-environment">Setting Up a Local Evaluation Environment</h3>
<p>For those interested in understanding Gemma 3’s capabilities through hands-on evaluation, I’ve found <a href="https://github.com/EleutherAI/lm-evaluation-harness">EleutherAI’s lm-evaluation-harness</a> to be an excellent tool. This framework provides standardized implementations of various benchmarks, enabling fair comparisons between models.</p>
<p>To prepare for local evaluation, I set up a virtual environment and installed the necessary dependencies:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and activate conda environment</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> lm-eval-harness python=3.10</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate lm-eval-harness</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Install lm-evaluation-harness</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/EleutherAI/lm-evaluation-harness.git</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> lm-evaluation-harness</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-e</span> .</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Install additional requirements for Hugging Face models</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install pytorch torchvision torchaudio <span class="at">-c</span> pytorch</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install accelerate transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="hands-on-evaluating-mmlu-pro-for-text-understanding" class="level3">
<h3 class="anchored" data-anchor-id="hands-on-evaluating-mmlu-pro-for-text-understanding">Hands-On: Evaluating MMLU-Pro for Text Understanding</h3>
<p>While Google has published impressive benchmark results, I wanted to verify these claims by running my own evaluations. MMLU-Pro is an enhanced version of the popular MMLU benchmark, featuring more challenging questions that require sophisticated reasoning. Unlike the original MMLU with four multiple-choice options, MMLU-Pro includes ten options per question, making random guessing much less effective.</p>
<p>To evaluate Gemma 3’s reasoning capabilities, I ran the 4B-IT model on the MMLU-Pro benchmark using this command:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lm_eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=google/gemma-3-4b-it <span class="at">--tasks</span> mmlu_pro <span class="at">--device</span> mps <span class="at">--batch_size</span> 16 <span class="at">--verbosity</span> INFO <span class="at">--write_out</span> <span class="at">--output_path</span> results <span class="at">--log_samples</span> <span class="at">--limit</span> 20 <span class="at">--num_fewshot</span> 0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This command loads the Gemma 3-4B-IT model from Hugging Face and evaluates it on a sample of the MMLU-Pro benchmark with 20 questions per subject. I used Apple’s Metal Performance Shaders (MPS) for hardware acceleration on my Mac and set a specific batch size to optimize throughput while staying within memory constraints.</p>
<p>The evaluation was conducted in a <strong>zero-shot setting</strong>, meaning no examples were provided to the model before testing. This is a more challenging evaluation approach as the model must solve problems without seeing similar examples first, making the results a clearer reflection of the model’s inherent capabilities rather than its ability to learn from examples.</p>
<section id="mmlu-pro-results" class="level4">
<h4 class="anchored" data-anchor-id="mmlu-pro-results">MMLU-Pro Results</h4>
<p>After running for approximately 25 minutes, the MMLU-Pro evaluation completed with the following results:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Category</th>
<th>Gemma 3-4B-IT (My Evaluation)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Biology</strong></td>
<td>45.0%</td>
</tr>
<tr class="even">
<td><strong>Business</strong></td>
<td>20.0%</td>
</tr>
<tr class="odd">
<td><strong>Chemistry</strong></td>
<td>15.0%</td>
</tr>
<tr class="even">
<td><strong>Computer Science</strong></td>
<td>35.0%</td>
</tr>
<tr class="odd">
<td><strong>Economics</strong></td>
<td>20.0%</td>
</tr>
<tr class="even">
<td><strong>Engineering</strong></td>
<td>20.0%</td>
</tr>
<tr class="odd">
<td><strong>Health</strong></td>
<td>40.0%</td>
</tr>
<tr class="even">
<td><strong>History</strong></td>
<td>35.0%</td>
</tr>
<tr class="odd">
<td><strong>Law</strong></td>
<td>15.0%</td>
</tr>
<tr class="even">
<td><strong>Math</strong></td>
<td>10.0%</td>
</tr>
<tr class="odd">
<td><strong>Other</strong></td>
<td>40.0%</td>
</tr>
<tr class="even">
<td><strong>Philosophy</strong></td>
<td>15.0%</td>
</tr>
<tr class="odd">
<td><strong>Physics</strong></td>
<td>10.0%</td>
</tr>
<tr class="even">
<td><strong>Psychology</strong></td>
<td>25.0%</td>
</tr>
<tr class="odd">
<td><strong>Overall</strong></td>
<td>24.6%</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Performance Analysis
</div>
</div>
<div class="callout-body-container callout-body">
<p>My local evaluation shows a significantly lower score (24.6%) than Google’s officially reported figure of 43.6% for the 4B model. This substantial discrepancy is likely due to several factors:</p>
<ol type="1">
<li><strong>Limited sample size</strong>: I only evaluated 20 questions per subject, which may not be representative of the full benchmark.</li>
<li><strong>Different evaluation configuration</strong>: My evaluation setup may differ from Google’s, including prompt formatting and evaluation parameters.</li>
<li><strong>Version differences</strong>: There may be differences in the specific version of MMLU-Pro or model weights used.</li>
</ol>
<p>It’s important to note that my testing represents a limited sampling rather than a comprehensive evaluation of the model’s capabilities.</p>
</div>
</div>
<p>Examining the performance across categories reveals that Gemma 3-4B-IT performs best on biology questions, achieving 45.0% accuracy in my evaluation. Health and other miscellaneous subjects also performed well at 40.0%. The model struggled most with math and physics questions, achieving only 10.0% accuracy, which highlights the challenges these models face with complex quantitative reasoning.</p>
<p>The most challenging questions for the model involved multi-step mathematical reasoning and specialized scientific concepts. For example, on problems requiring knowledge of advanced calculus or quantum physics, the model often struggled to produce the correct answer, despite generating plausible-sounding explanations.</p>
</section>
</section>
<section id="practical-insights-from-hands-on-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="practical-insights-from-hands-on-evaluation">Practical Insights from Hands-On Evaluation</h3>
<p>My experience with Gemma 3 provides several insights that can help you make informed decisions about using these models:</p>
<ol type="1">
<li><p><strong>Limited Testing vs.&nbsp;Full Benchmarks</strong>: My evaluation used a small sample (20 questions per subject), which may explain some of the differences between my results and Google’s reported figures. While limited, these tests still provide valuable insights into the model’s strengths and weaknesses.</p></li>
<li><p><strong>Resource Efficiency</strong>: Running these evaluations on consumer hardware (Mac with M2 chip) was feasible, though time-consuming. This confirms Google’s claims about Gemma 3’s efficiency compared to larger models that require specialized infrastructure.</p></li>
<li><p><strong>Subject Matter Variability</strong>: The model’s performance varied significantly across subjects. The 4B model showed strengths in biology (45%), health (40%), and business-related content, but struggled with math and physics (10% each). This suggests careful consideration of your specific use case is important when selecting a model size.</p></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Recommendation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Based on my limited testing, the 4B model may be sufficient for applications involving document understanding, biology, health, or business content. However, for applications requiring strong mathematical reasoning or physics knowledge, Google reports the larger 12B or 27B variants would likely be worth the additional computational cost.</p>
</div>
</div>
</section>
<section id="overcoming-common-challenges" class="level3">
<h3 class="anchored" data-anchor-id="overcoming-common-challenges">Overcoming Common Challenges</h3>
<p>During my evaluation, I encountered several practical challenges worth noting:</p>
<ol type="1">
<li><p><strong>Memory Requirements</strong>: Even the 4B model required substantial RAM (&gt;16GB) when evaluating multimodal tasks with a reasonable batch size.</p></li>
<li><p><strong>Evaluation Time</strong>: The full benchmarks took several hours to complete, which could be prohibitive for rapid experimentation cycles.</p></li>
<li><p><strong>Prompt Sensitivity</strong>: I noticed that small changes in prompt formatting could sometimes lead to different results, suggesting some sensitivity to the exact evaluation setup.</p></li>
</ol>
<p>For those looking to conduct their own evaluations, I recommend starting with a smaller subset of the benchmarks to get familiar with the process before running full evaluations. Additionally, carefully reviewing the documentation for each benchmark will help ensure your evaluation setup matches the intended configuration.</p>
</section>
<section id="additional-resources-for-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="additional-resources-for-evaluation">Additional Resources for Evaluation</h3>
<p>If you’re interested in conducting your own evaluations or learning more about the benchmarks used in this analysis, here are some helpful resources:</p>
<ul>
<li><a href="https://github.com/EleutherAI/lm-evaluation-harness">EleutherAI’s lm-evaluation-harness</a> - The evaluation framework used in this post</li>
<li><a href="https://github.com/MMLU-Pro/MMLU-Pro">MMLU-Pro Benchmark</a> - Official repository for the MMLU-Pro benchmark</li>
<li><a href="https://huggingface.co/google/gemma-3-4b-it">Hugging Face Model Cards</a> - Detailed information about the Gemma 3 models</li>
</ul>
<p>By running these benchmarks yourself, you can gain a deeper understanding of how Gemma 3 might perform in your specific use cases and compare it against other models in a controlled, standardized setting.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Gemma 3 represents a <strong>significant step forward</strong> in making powerful AI accessible to developers. By finding the sweet spot between computational efficiency and model performance, Google has created a versatile family of models that can run on modest hardware while delivering impressive capabilities. Whether you’re building applications that require image analysis, multilingual support, or complex reasoning, Gemma 3 offers a compelling option that doesn’t demand massive computational resources.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why Gemma 3 Matters
</div>
</div>
<div class="callout-body-container callout-body">
<p>Gemma 3 democratizes access to advanced AI by making high-performance models available with reasonable hardware requirements. This opens the door for smaller organizations, academic researchers, and individual developers to create sophisticated AI applications that were previously only possible for large tech companies.</p>
</div>
</div>
<p>Available through <strong>Google AI Studio</strong>, the <strong>NVIDIA API Catalog</strong>, <strong>Hugging Face</strong>, <strong>Ollama</strong>, and <strong>Kaggle</strong>, Gemma 3 continues Google’s commitment to open and accessible AI technology. For developers seeking to incorporate advanced AI capabilities into their applications without the need for extensive infrastructure, Gemma 3 presents an attractive and powerful solution.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://blog.google/technology/developers/gemma-3/">Google’s Blog: Introducing Gemma 3</a></li>
<li><a href="https://huggingface.co/blog/gemma3">Hugging Face: Gemma 3 Analysis</a></li>
<li><a href="https://www.zdnet.com/article/google-claims-gemma-3-reaches-98-of-deepseeks-accuracy-using-only-one-gpu/">ZDNet: Google claims Gemma 3 reaches 98% of DeepSeek’s accuracy using only one GPU</a></li>
<li><a href="https://www.perplexity.ai/page/google-unveils-gemma-3-ai-mode-.cGGCsMoSo2X_pTrtcBw_Q">Perplexity AI: Google unveils Gemma 3 AI model</a></li>
<li><a href="https://developers.googleblog.com/en/introducing-gemma3/">Google Developers Blog: Introducing Gemma 3</a></li>
<li><a href="https://learnprompting.org/blog/google-gemma-3-introduced">Learn Prompting: Google Gemma 3 Introduced</a></li>
<li><a href="https://www.storagereview.com/news/google-gemma-3-and-amd-instella-advancing-multimodal-and-enterprise-ai">Storage Review: Google Gemma 3 and AMD Instella advancing multimodal and enterprise AI</a></li>
<li><a href="https://blog.roboflow.com/gemma-3/">Roboflow Blog: Gemma 3</a></li>
</ul>
</section>
<section id="appendix-reproducing-the-benchmark-results" class="level2">
<h2 class="anchored" data-anchor-id="appendix-reproducing-the-benchmark-results">Appendix: Reproducing the Benchmark Results</h2>
<p>If you’re interested in running these benchmarks yourself, you can use the EleutherAI’s lm-evaluation-harness tool. Here’s the command I used to evaluate the Gemma 3-4B-IT model on the MMLU-Pro benchmark:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and activate a conda environment</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> lm-eval-harness python=3.10</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate lm-eval-harness</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Install lm-evaluation-harness</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/EleutherAI/lm-evaluation-harness.git</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> lm-evaluation-harness</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-e</span> .</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Install additional requirements for Hugging Face models</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install pytorch torchvision torchaudio <span class="at">-c</span> pytorch</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install accelerate transformers</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the MMLU-Pro benchmark with a limited sample size</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="ex">lm_eval</span> <span class="at">--model</span> hf <span class="at">--model_args</span> pretrained=google/gemma-3-4b-it <span class="at">--tasks</span> mmlu_pro <span class="at">--device</span> mps <span class="at">--batch_size</span> 16 <span class="at">--verbosity</span> INFO <span class="at">--write_out</span> <span class="at">--output_path</span> results <span class="at">--log_samples</span> <span class="at">--limit</span> 20 <span class="at">--num_fewshot</span> 0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This command will evaluate the model on 20 questions from each subject area in the MMLU-Pro benchmark. You can remove the <code>--limit 20</code> parameter to evaluate on the full benchmark, but be aware that this will take significantly longer.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/slyracoon23\.github\.io\/blog");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "Slyracoon23/blog";
    script.dataset.repoId = "R_kgDOOD0L5w";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOOD0L584CopEq";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "bottom";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><i class="fa-regular fa-copyright" aria-label="copyright"></i> Copyright 2025, Earl Potters</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>