---
aliases:
- /ai-engineer-worlds-fair/
categories:
- AI
date: '2025-06-06'
image: /images/ai_engineer_worlds_fair/thumbnail.png
title: "AI Engineer's World's Fair 2025: Personal Experience"
subtitle: "A look at the AI Engineer's World's Fair 2025"
format: html
---

![AI Engineer's World's Fair 2025](images/paste-13.png)


This blog post will go over my recent experience of the AI Engineer Worlds Fair 2025. I wanted to recount the events and experience when it's still fresh in my mind.

## Brief Introduction

The AI Engineer's World's Fair is a conference in San Francisco that brings AI practitioners and researchers alike. The conference is meant to showcase the latest advancements and innovation in the space. 

The conference is an amazing way to collaborate, network, learn and connect with the leading industry leaders and researchers. This gives you a glimpse of what is on the horizon and what opportunities lie ahead. It's mainly the reason why I've gone to it a second time in a row so far. 

Before attending the event, I had hoped to receive several things from this event.

1. Connect with entrepreneurs, founders, researchers and amazing people

2. Learn about latest advancements in agents and models

3. Find next opportunities for work in the space

Needless to say I had gotten all of them plus much more.

## Event Overview

The AI Engineer's World's Fair 2025 was absolutely massive - **3,000 attendees** packed into San Francisco's Marriott Marquis from June 3-5. This was double the size of last year's event, which really showed how fast the AI engineering community is growing. The organizers positioned it as "NeurIPS for Engineers," and honestly, that description felt spot on.

What struck me most was how practical everything was. This wasn't another conference full of theoretical research papers. Instead, it was focused entirely on people who are **actually shipping AI systems to production**. Every session, every workshop, every conversation was about real-world implementation challenges and battle-tested solutions.

The three-day structure worked really well:

**Day 1** was pure workshop immersion - over 20 hands-on sessions covering everything from prompt engineering to voice AI to agent orchestration. These weren't your typical "follow along" tutorials either. The "bring your prompts" format was genius - you could actually work on your real production prompts with experts.

**Day 2** kicked off the main conference with industry keynotes and the expo hall opening. AWS, Microsoft, and Google all had major presence, but what was refreshing was seeing the OpenAI and Anthropic teams sharing actual implementation details rather than just product demos.

**Day 3** featured the most advanced technical sessions and intimate fireside chats with industry leaders. The after-parties were where some of the best conversations happened - there's something about grabbing a drink that makes people share the real challenges they're facing.

With 18 tracks and 150+ sessions running concurrently, the hardest part was choosing what to attend. But having everything recorded with 18-minute time limits kept things focused and information-dense.

## Key Highlights and Sessions

### Day 1: Workshop Deep Dive

Day 1 was all about getting your hands dirty. The workshop day featured over 20 sessions, and the variety was incredible. What I loved most was the \"hands-on keyboard\" philosophy - no death by PowerPoint here.

The **Voice AI workshops** were probably the most impressive. Shrestha Basu Mallick from Google DeepMind and Kwindla Kramer from Daily/Pipecat walked us through building actual real-time conversational experiences. We're talking sub-100ms latency, browser-based voice apps that you could deploy immediately. They had pre-configured accounts ready, so within minutes you were building production-quality voice agents.

The **\"Bring Your Prompts\"** sessions were genius. Instead of generic prompt engineering theory, you could bring your actual production prompts and workshop them with experts who optimize prompts for a living. I brought a few complex reasoning prompts I'd been struggling with, and the feedback was invaluable.

What really stood out was the **AI productivity track** with Kevin Ball and Manuel Odendahl. These weren't basic \"how to use ChatGPT\" sessions. We dove deep into .cursorrules optimization, advanced Cursor workflows, and productivity patterns that can genuinely transform how you work. I picked up techniques that I immediately started using the next day.

The **agent orchestration workshops** tackled the real challenges - reliability, error handling, and deployment patterns. It's one thing to build a demo agent; it's another to build one that works consistently in production. The focus on practical reliability patterns was exactly what I needed.


### Day 2: Industry Heavyweights and Technical Deep Dives

Day 2 was when things got serious. The expo hall opened, and suddenly you had access to every major player in AI infrastructure. But what impressed me most was the technical depth of the industry presentations.

**AWS kicked things off** with their Bedrock platform and the newly announced Nova model family. But this wasn't your typical cloud vendor pitch. They dove deep into enterprise deployment patterns, specifically for regulated industries. Seeing how they handle multi-billion parameter model inference at scale was eye-opening. The engineering challenges of maintaining sub-second response times across global infrastructure are no joke.

**Microsoft's Azure AI Studio team** shared some fascinating insights about hybrid AI architectures. They talked about the real engineering challenges of deploying AI features across their massive user base - think Office and Windows AI features serving hundreds of millions of users simultaneously. The reliability requirements are insane when you're at that scale.

The **Google DeepMind sessions** were incredibly technical. They went deep on Gemini API integration patterns and multimodal capabilities. What stood out was their focus on real-time integration - building conversational AI that can handle voice, video, and text simultaneously with consistent performance.

With 9 specialized tracks running concurrently, I had to make some tough choices. I spent most of my time bouncing between the **Computer Use Agents** track (autonomous systems that can actually interact with software interfaces) and **Production Evaluation Systems** (because measuring AI system performance in production is still an unsolved problem).

The expo format was perfect - technical demonstrations over marketing fluff. Every exhibitor had to provide hands-on experiences or detailed technical content. I spent hours at the Temporal booth learning about workflow orchestration patterns for agent systems.


### Day 3: Advanced Architectures and Real Talk

Day 3 was where the conference really showed its depth. The most technically advanced sessions, intimate fireside chats, and the kind of honest conversations about AI engineering that you rarely hear in public.

The **production-ready agent architecture sessions** were exactly what I came for. Multiple speakers tackled the elephant in the room: building agents that don't break in production. We're talking about systems that can reliably interact with external APIs, handle edge cases gracefully, and maintain consistent performance when users throw unexpected inputs at them.

The **advanced technical tracks** covered next-generation tooling, enterprise platform architecture, and real-time AI system design. One session on production monitoring for AI applications was particularly eye-opening - traditional APM tools just don't cut it when you're dealing with probabilistic systems.

But honestly, the **fireside chats** were where I got the most value. Technical leaders sharing the stuff they don't usually talk about in public: technical debt in AI systems, hiring challenges (spoiler: everyone's struggling to find good AI engineers), and the painful lessons learned from production AI failures.

The **Model Context Protocol (MCP) integration sessions** deserve special mention. This is becoming critical infrastructure for agent systems, and seeing practical implementation patterns was invaluable. The authentication and service discovery challenges are real, and the solutions being shared were battle-tested.

The after-parties were worth staying for. There's something about informal conversations over drinks that brings out the real challenges people are facing. I had more meaningful technical discussions in those few hours than in most conference hallway tracks.


## Notable Speakers and Key Insights

The speaker lineup was incredible - a ~6% acceptance rate from over 500 applications meant every session was high-quality. Here are the standouts that really stuck with me:

**Shrestha Basu Mallick** (Google DeepMind) didn't just demo the Gemini API - she showed us how to build production multimodal systems that actually scale. Her insights about handling millions of concurrent users while maintaining consistent response times were invaluable.

**Kwindla Kramer** (Daily/Pipecat CEO) shared the real engineering challenges behind sub-100ms voice AI systems. The WebRTC complexities, edge case handling, and infrastructure decisions required for enterprise voice agents - this was the kind of technical depth you rarely see.

**Sean DuBois** (OpenAI/Pion) gave one of the most technically intensive presentations on realtime systems design. His coverage of WebRTC protocols and real-time media processing was mind-bending. If you're building anything with real-time AI interactions, his session was essential.

What made this conference special was that every speaker was a practitioner first. These weren't theoretical presentations - they were battle-tested insights from people shipping AI systems to millions of users. The 18-minute format kept everything focused and eliminated fluff.

The themes that emerged were clear: **agents are becoming the dominant paradigm**, production reliability is the new frontier, and AI engineering is legitimately becoming its own discipline separate from traditional ML engineering.

## Personal Takeaways

Walking away from the World's Fair, I'm convinced we're at a genuine inflection point in AI engineering. This isn't just hype - the practical focus and production-ready solutions being shared show that the industry is maturing rapidly.

**Agents are everywhere.** Every conversation, every session, every demo somehow touched on agent architectures. But what's different now is the focus on reliability and production deployment. People aren't just building cool demos anymore; they're building systems that need to work consistently for real users.

**Infrastructure is catching up.** The tooling ecosystem is finally robust enough to support production AI systems. From Temporal for workflow orchestration to specialized monitoring tools for probabilistic systems, the infrastructure pieces are coming together.

**The community is incredible.** The quality of conversations and the willingness to share real challenges (not just successes) made this event special. I came away with a notebook full of implementation ideas and a contact list of people facing similar challenges.

**AI engineering is its own discipline.** This conference proved that AI engineering isn't just software engineering with some ML sprinkled in. It requires different patterns, different tools, and different ways of thinking about reliability and user experience.

My biggest takeaway? The future is being built right now by practitioners who are solving real problems with production AI systems. The theoretical research is important, but the action is happening in the trenches with engineers who are actually shipping code.


## Conclusion

The AI Engineer's World's Fair 2025 lived up to its reputation as the premier gathering for production AI practitioners. Doubling in size while maintaining its focus on practical, battle-tested solutions, it proved that AI engineering has truly emerged as its own professional discipline.

What sets this conference apart is its relentless focus on implementation over speculation. Every session, every workshop, every conversation was grounded in real-world deployment challenges. This isn't a conference for theoretical discussions about what AI might do someday - it's for engineers who are building AI systems that work today.

The themes that emerged - agent-first architectures, production reliability, infrastructure maturation - are shaping the industry's direction for 2025 and beyond. More importantly, the community that's forming around these challenges is exceptional. The willingness to share failures alongside successes creates an environment where real learning happens.

If you're building production AI systems, the World's Fair should be on your calendar. The combination of cutting-edge technical content, hands-on workshops, and genuine community makes it worth the investment. Plus, the after-parties are where the real insights happen.

See you at next year's event - I have a feeling it's going to be even bigger.
