---
aliases:
- /ai-engineer-worlds-fair/
categories:
- AI
date: '2025-06-06'
image: /images/ai_engineer_worlds_fair/thumbnail.png
title: "AI Engineer's World's Fair 2025: Personal Experience"
subtitle: "A look at the AI Engineer's World's Fair 2025"
format: html
---

![AI Engineer's World's Fair 2025](images/paste-13.png)

This blog post will go over my recent experience of the AI Engineer Worlds Fair 2025. I wanted to recount the events and experience when it's still fresh in my mind.

## Brief Introduction

The AI Engineer's World's Fair is a conference in San Francisco that brings AI practitioners and researchers alike. The conference is meant to showcase the latest advancements and innovation in the space.

The conference is an amazing way to collaborate, network, learn and connect with the leading industry leaders and researchers. This gives you a glimpse of what is on the horizon and what opportunities lie ahead. It's mainly the reason why I've gone to it a second time in a row so far.

Before attending the event, I had hoped to receive several things from this event.

1.  Connect with entrepreneurs, founders, researchers and amazing people

2.  Learn about latest advancements in agents and models

3.  Find next opportunities to work on in the space

Needless to say I had gotten all of them plus much more.

## Event Overview

The AI Engineer's World's Fair 2025 was absolutely massive - **3,000 attendees** packed into San Francisco's Marriott Marquis from June 3-5. This was double the size of last year's event, which really showed how fast the AI engineering community is growing. The organizers positioned it as "NeurIPS for Engineers," and honestly, that description felt spot on.

What struck me most was how practical everything was. This wasn't another conference full of theoretical research papers. Instead, it was focused entirely on people who are **actually shipping AI systems to production**. Every session, every workshop, every conversation was about real-world implementation challenges and battle-tested solutions.

The three-day structure worked really well:

**Day 1** was pure workshop immersion - over 20 hands-on sessions covering everything from prompt engineering to voice AI to agent orchestration. These weren't your typical "follow along" tutorials either. The "bring your prompts" format was genius - you could actually work on your real production prompts with experts.

**Day 2** kicked off the main conference with industry keynotes and the expo hall opening. AWS, Microsoft, and Google all had major presence, but what was refreshing was seeing the OpenAI and Anthropic teams sharing actual implementation details rather than just product demos.

**Day 3** featured the most advanced technical sessions and intimate fireside chats with industry leaders. The after-parties were where some of the best conversations happened - there's something about grabbing a drink that makes people share the real challenges they're facing.

With 18 tracks and 150+ sessions running concurrently, the hardest part was choosing what to attend. The track variety was incredible - from MCP (Model Context Protocol) to GraphRAG, from Tiny Teams to AI Architects. Having everything recorded with 18-minute time limits kept things focused and information-dense.

## Key Highlights and Sessions

### Day 1: Workshop Deep Dive

Day 1 was all about getting your hands dirty. I chose two workshops that really aligned with where I wanted to deepen my technical knowledge, and both delivered exactly what I was hoping for.

**Advanced: Reinforcement Learning, Kernels, Reasoning, Quantization & Agents** by Daniel Han (9:00 AM, Foothill C) was fantastic. Daniel was such a funny guy and really kept the crowd engaged throughout the entire 2-hour session. He went deep into the fundamentals of RL in a way that was both accessible and technically rigorous.

![](images/paste-1.jpeg)

My key takeaways: You need to have SFT (Supervised Fine-Tuning) first to get the right format and basic reasoning capabilities in place, then using RL can get you significant improvements from there. The discussion about quantization was insightful - seeing how models like DeepSeek-R1 can be quantized down to 1.58-bits while maintaining performance was incredible. The conversations throughout were really engaging, with lots of back-and-forth between Daniel and the audience.

::: callout-note
## Dynamic 4-bit Quantization - A Follow-up Learning Goal

Daniel's workshop sparked my interest in **Dynamic 4-bit Quantization**, which I definitely want to dive deeper into. Here's what I learned from researching this technique:

**What is Dynamic 4-bit Quantization?** - Reduces neural network memory requirements by **4x** (from 32-bit floats to 4-bit integers) - Computes activation ranges **on-the-fly at runtime** rather than using pre-computed static ranges - Enables substantial memory and power savings for model deployment

**Key Benefits:** - **Memory Efficiency**: 4x reduction in storage requirements for weights and activations - **Power Savings**: Energy consumption dominated by memory access gets significantly reduced - **Flexible Precision**: Can adapt quantization ranges dynamically based on input data

**Recent Advances:** - **Post-Training Approaches**: No need for fine-tuning or full dataset access - **GPTQ Method**: Specifically designed for large language models like GPT - **4.6-bit Schemes**: Novel approaches that balance accuracy and efficiency

**The Trade-off**: While 4-bit quantization can introduce some quality loss compared to 8-bit or full precision, recent research shows it's possible to maintain near-original accuracy with proper techniques.

This connects perfectly to Daniel's discussion about DeepSeek-R1's extreme quantization - understanding dynamic 4-bit quantization could be key to building efficient production AI systems.
:::

Personal note: I'm a big fan of Unsloth for fine-tuning work, so hearing Daniel's thoughts on efficient training techniques really resonated with me.

The afternoon **Prompt Engineering & AI Red Teaming** session with Sander Schulhoff (3:30 PM, SOMA) was equally valuable. While waiting in line, I got to chat with an ML researcher from Instacart about the current state of prompt engineering, which was a nice warm-up to the session.

Sander covered what prompt engineering really is and emphasized that prompts are still a core technique used across many applications. He spent significant time on "prompt injection" and jailbreaks, which are apparently still major issues even today. The interactive red teaming competition at the end was both educational and fun.

He runs [HackAPrompt.com](https://www.hackaprompt.com), the world's first AI red teaming competition platform - maybe I should test my prompt skills there and see if I can flex a bit ðŸ˜„

Personal take: Seriously though, I honestly don't like that prompt engineering is a thing we have to deal with, but it's clearly not going away anytime soon as far as I can see. The fact that we still need these techniques shows we're not quite at the point where models just "understand" what we want naturally.

### Day 2: Industry Heavyweights and Technical Deep Dives

I arrived around 8:30 AM to grab breakfast - they were serving small croissants, pastries, and fruit. After that, we were corralled into the massive keynote hall that housed over 1,000 people, with a large stage and impressive side projectors.

Swyx kicked us off around 9:00 AM, mentioning how the event had doubled in size from last year. One insight that really stuck with me was his mental model shift: instead of getting caught up in definitions of what constitutes an "agent," think about the ratio of AI to human work - 1:1, 1:10, 1:100? I really like this classification as a useful framework.

**Microsoft's Asha Sharma keynote** was impressive in terms of presentation quality - they really had the animations and flow down perfectly. The demo went off the rails though when they demonstrated an agent that was slow with internet connectivity and would just speak over you. The woman on stage kept saying "AWESOME" trying to get the LLM to stop talking, which only prompted it to talk more! This caused delays for all subsequent speakers, and the internet was down throughout.

**Sarah Guo's VC talk on "State of Startups and AI 2025"** was actually excellent. She managed to keep the crowd engaged despite the technical difficulties. Her thesis was that AI applications will broaden, and the moat is execution - speed and execution are the name of the game. I pretty much agree, though when she talks about execution, I think the human/customer side is more important than just code nowadays.

**Simon Willison's "2025 in LLMs so far"** was characteristically funny. He gave a humorous benchmark about pelicans on a bike, and it's actually incredible how models are getting better at these bizarre tasks - quite remarkable progress.

After the morning keynotes, I went straight to the expo hall. I was on a mission to really check out the companies and get to know them personally.

![](images/paste-3.jpeg)

I stayed in the expo hall until midday when lunch was being served. The food was really good - rice, beef, and avocado. I even met a guy who was head of Linear, which was super cool! After lunch, I caught some of the afternoon sessions.

I was planning to meet up with a friend, Ronan from Trelis Research - I'm a long-term subscriber to his YouTube channel and really wanted to meet him in person. Luckily, I was able to attend some excellent infrastructure talks beforehand.

**Infrastructure Track Sessions** were incredibly insightful:

**Dylan Patel's "Geopolitics of AI Infrastructure"** was packed - I could only catch bits from standing in the doorway since the room was completely full. His insights about nations racing to secure critical AI hardware and control compute capacity were eye-opening.

**Kyle Kranen's "Hacking the Inference Pareto Frontier"** showed how prefill and disaggregation techniques achieve speedups. It was fascinating to see the many techniques available to adjust the curve between cost, quality, and latency.

**Robert Wachen's "Flipping the Inference Stack"** drew analogies to how the iPhone enabled Uber and similar platforms. His key point: we're moving into an inference-dominated world where most compute will be generated, and inference will become the bottleneck for many applications.

I briefly talked with Ronan - if you don't know his content, you should definitely check it out. Really excellent stuff!

**AWS kicked things off** with their Bedrock platform and the newly announced Nova model family. But this wasn't your typical cloud vendor pitch. They dove deep into enterprise deployment patterns, specifically for regulated industries. Seeing how they handle multi-billion parameter model inference at scale was eye-opening. The engineering challenges of maintaining sub-second response times across global infrastructure are no joke.

**Microsoft's Azure AI Studio team** shared some fascinating insights about hybrid AI architectures. They talked about the real engineering challenges of deploying AI features across their massive user base - think Office and Windows AI features serving hundreds of millions of users simultaneously. The reliability requirements are insane when you're at that scale.

The **Google DeepMind sessions** were incredibly technical. They went deep on Gemini API integration patterns and multimodal capabilities. What stood out was their focus on real-time integration - building conversational AI that can handle voice, video, and text simultaneously with consistent performance.

With specialized tracks like **MCP**, **LLM RecSys**, **Agent Reliability**, and **Voice AI** running concurrently, I had to make some tough choices. I spent most of my time bouncing between the **Agent Reliability** track (focusing on making agents that actually work in production) and **AI Infrastructure** (because the tooling ecosystem is finally catching up to our ambitions).

I headed downstairs where they were serving snacks just before the final keynotes of Day 2.

**Final Day 2 Keynotes:**

**AWS's agentic services presentation** was first, though I don't remember most of the details.

**Windsurf** was particularly interesting as they're expanding beyond just the developer stack. This made me a bit concerned - what was I going to do? Was I going to just click "accept"? Was my task reduced to prompting and clicking either accept or reject? It's incredible technology but also a little concerning, especially since I'm on the forefront of using this kind of tech.

**Greg Brockman's keynote** was the main highlight. He has an impressive track record - really insane actually. A few key points caught my attention:

1. **AI is a full infrastructure problem** - it's not one thing, it's everything: money, hardware, software, people, etc.

2. **We're back to "basic research"** - the transformer architecture is strong, but new advancements need to be made to push the frontier.

3. **Personal takeaway**: I need to use this new technology to upskill and expand myself, especially as things are growing even more rapidly.

The expo format was perfect - technical demonstrations over marketing fluff. Every exhibitor had to provide hands-on experiences or detailed technical content. I spent hours at the Temporal booth learning about workflow orchestration patterns for agent systems.

### Day 3: Advanced Architectures and Real Talk

Same as Day 2, I arrived around 8:30 AM to grab breakfast - they were serving the same croissants, fruits, and small pastries. We kicked off strong right away.

**Logan Kilpatrick's Gemini presentation** started us off. I remember he was part of OpenAI last year before switching to Gemini, but Gemini has been incredibly strong. They've shipped so many excellent features - it's become a really solid product. I use it for YouTube and vision tasks regularly. Gemini is genuinely my go-to model for vision work.

**Jack Rae's "Thinking Deeper in Gemini"** talk about thinking was fascinating. Thinking is really a new paradigm that adds a dimension that's super interesting. It actually increases latency and cost but dramatically improves quality. Figuring out how to control thinking is going to be incredibly effective, especially when paired with tool calling.

**Manu Goyal's "Why should anyone care about Evals?"** was just funny. I'm sure Braintrust has good evals, but it's still about iterating on prompts, which remains very challenging.

**Solomon Hykes' "Containing Agent Chaos"** was particularly interesting, and I really need to try their tools. They're from Dagger and are open source. He literally open-sourced on stage and got 13k stars within 20 minutes - that's insane for an audience of only 3k people. Their idea is simple but brilliant: Docker + Git + LLMs. Super simple, but I think I want to start using that pattern on my machine when it's more stable. I can see it being a powerful primitive.

**Jesse Han's "The infrastructure for the singularity"** from Morph was weird. I love their artwork - it's actually amazing and I want to understand how they created the art more than the tech. The tech I can figure out. The presentation felt like a "sermon" or had religious undertones about LLMs, which was slightly uncomfortable, then they revealed they're just a browser/desktop sandbox.

Day 3 was where the conference really showed its depth. The most technically advanced sessions, intimate fireside chats, and the kind of honest conversations about AI engineering that you rarely hear in public.

The **production-ready agent architecture sessions** were exactly what I came for. Multiple speakers tackled the elephant in the room: building agents that don't break in production. We're talking about systems that can reliably interact with external APIs, handle edge cases gracefully, and maintain consistent performance when users throw unexpected inputs at them.

After the morning talks, I walked around the expo again until I met up with another friend, David, who showed up randomly. He's starting his startup and I introduced him to some companies that might help.

**Reasoning + RL Track Sessions:**

I attended several excellent RL sessions:

**Will Brown's "Training Agentic Reasoners"** - I only briefly caught this, but the essence was doing RL with tool calling and integrating this with training. I think this approach will provide some of the most significant rewards.

**Greg Kamradt's "Measuring AGI: Interactive Reasoning Benchmarks"** was super cool. They mentioned releasing a preview of interactive game-like tasks, reminiscent of Halite. The main takeaway: giving agents an environment with no predefined goal - they need to figure out objectives on their own.

**Kyle Corbitt's "How to Train Your Agent: Building Reliable Agents with RL"** and **Nathan Lambert's "A taxonomy for next-generation reasoning models"** were higher-level overviews, but really covered similar ground.

I also attended **Philip Kiely's "Optimizing inference for voice models in production"** which was very informative.

The **advanced technical tracks** included **SWE-Agents** (autonomous software engineering), **Reasoning + RL** (the new frontier of inference-time scaling), **Evals** (finally getting serious about measuring AI system performance), **Retrieval + Search** (going beyond basic RAG), and **Security** (critical as agents get more access). One session on production monitoring for AI applications was particularly eye-opening - traditional APM tools just don't cut it when you're dealing with probabilistic systems.

But honestly, the **fireside chats** were where I got the most value. Technical leaders sharing the stuff they don't usually talk about in public: technical debt in AI systems, hiring challenges (spoiler: everyone's struggling to find good AI engineers), and the painful lessons learned from production AI failures.

The **Model Context Protocol (MCP) integration sessions** deserve special mention. This is becoming critical infrastructure for agent systems, and seeing practical implementation patterns was invaluable. The authentication and service discovery challenges are real, and the solutions being shared were battle-tested.

I got to chat with a friend from the AI Engineering hackathon after lunch, then headed into the final keynotes.

**Final Day 3 Keynotes:**

**Micah Hill-Smith and George Cameron's "Trends Across the AI Frontier"** highlighted how we're living in an increasingly multimodal world.

**Sean Grove's "Prompt Engineering is Dead - Everything is a Spec"** from OpenRouter was particularly interesting. His thesis: prompts should be your "spec" - the most important document, with "code" or any "artifacts" just being results from the spec. It's an interesting idea that I'm definitely going to try out.

After walking out, I got to see friends from the AI Engineering hackathon and say goodbye to people I'd met. We decided to go to the RunPod after-party, which was actually awesome - a wonderful closing party with amazing people, conversations, and drinks.

I got back at 10:30 PM, and that was that. Overall, I was extremely happy with the experience. I achieved everything I set out to do and will be following up on people, concepts, and getting back on track with full vigor.

The after-parties were worth staying for. There's something about informal conversations over drinks that brings out the real challenges people are facing. I had more meaningful technical discussions in those few hours than in most conference hallway tracks.

## Notable Speakers and Key Insights

The speaker lineup was incredible - a \~6% acceptance rate from over 500 applications meant every session was high-quality. Here are the standouts that really stuck with me:

**Shrestha Basu Mallick** (Google DeepMind) didn't just demo the Gemini API - she showed us how to build production multimodal systems that actually scale. Her insights about handling millions of concurrent users while maintaining consistent response times were invaluable.

**Kwindla Kramer** (Daily CEO) shared the real engineering challenges behind sub-100ms voice AI systems. The WebRTC complexities, edge case handling, and infrastructure decisions required for enterprise voice agents - this was the kind of technical depth you rarely see.

**Sean DuBois** (OpenAI/Pion) gave one of the most technically intensive presentations on realtime systems design. His coverage of WebRTC protocols and real-time media processing was mind-bending. If you're building anything with real-time AI interactions, his session was essential.

What made this conference special was that every speaker was a practitioner first. These weren't theoretical presentations - they were battle-tested insights from people shipping AI systems to millions of users. The 18-minute format kept everything focused and eliminated fluff.

The themes that emerged were clear: **agents are becoming the dominant paradigm**, production reliability is the new frontier, and AI engineering is legitimately becoming its own discipline separate from traditional ML engineering.

## Personal Takeaways

Walking away from the World's Fair, I'm convinced we're at a genuine inflection point in AI engineering. This isn't just hype - the practical focus and production-ready solutions being shared show that the industry is maturing rapidly.

**Agents are everywhere.** Every conversation, every session, every demo somehow touched on agent architectures. But what's different now is the focus on reliability and production deployment. People aren't just building cool demos anymore; they're building systems that need to work consistently for real users.

**Infrastructure is catching up.** The tooling ecosystem is finally robust enough to support production AI systems. From Temporal for workflow orchestration to specialized monitoring tools for probabilistic systems, the infrastructure pieces are coming together.

**The community is incredible.** The quality of conversations and the willingness to share real challenges (not just successes) made this event special. I came away with a notebook full of implementation ideas and a contact list of people facing similar challenges.

**AI engineering is its own discipline.** This conference proved that AI engineering isn't just software engineering with some ML sprinkled in. It requires different patterns, different tools, and different ways of thinking about reliability and user experience.

My biggest takeaway? The future is being built right now by practitioners who are solving real problems with production AI systems. The theoretical research is important, but the action is happening in the trenches with engineers who are actually shipping code.

## Conclusion

The AI Engineer's World's Fair 2025 lived up to its reputation as the premier gathering for production AI practitioners. Doubling in size while maintaining its focus on practical, battle-tested solutions, it proved that AI engineering has truly emerged as its own professional discipline.

What sets this conference apart is its relentless focus on implementation over speculation. Every session, every workshop, every conversation was grounded in real-world deployment challenges. This isn't a conference for theoretical discussions about what AI might do someday - it's for engineers who are building AI systems that work today.

The themes that emerged - agent-first architectures, production reliability, infrastructure maturation - are shaping the industry's direction for 2025 and beyond. More importantly, the community that's forming around these challenges is exceptional. The willingness to share failures alongside successes creates an environment where real learning happens.

If you're building production AI systems, the World's Fair should be on your calendar. The combination of cutting-edge technical content, hands-on workshops, and genuine community makes it worth the investment. Plus, the after-parties are where the real insights happen.

See you at next year's event - I have a feeling it's going to be even bigger.