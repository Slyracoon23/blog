---
title: "#19566 - [Perf] Further tunings for SM100 FP8 CUTLASS kernel"
description: "Additional performance optimizations for SM100 FP8 CUTLASS GEMM kernels with targeted configurations for different matrix dimensions"
categories: [performance, cutlass, fp8, sm100, gpu-optimization]
date: "2025-06-21"
---

## [#19566](https://github.com/vllm-project/vllm/pull/19566) - [Perf] Further tunings for SM100 FP8 CUTLASS kernel

#### Overview
- Performance optimization for SM100 (Blackwell B200) FP8 CUTLASS GEMM kernels following previous work in PR #18778
- Introduces specialized CUTLASS configurations optimized for different matrix M dimensions (batch sizes)
- Demonstrates significant speedups (1.13x-1.4x) across various matrix dimensions, particularly effective for M=128-256 range

#### Code Changes (Verified)
**File**: `csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm100_fp8_dispatch.cuh`

```diff
@@ -15,11 +15,25 @@ using c3x::cutlass_gemm_caller;
 template <typename InType, typename OutType,
           template <typename, typename, typename> typename Epilogue>
 struct sm100_fp8_config_default {
-  // M in (128, inf)
+  // M in (256, inf)
   static_assert(std::is_same<InType, cutlass::float_e4m3_t>());
   using KernelSchedule = cutlass::gemm::collective::KernelScheduleAuto;
   using EpilogueSchedule = cutlass::epilogue::collective::EpilogueScheduleAuto;
-  using TileShape = Shape<_256, _128, _64>;
+  using TileShape = Shape<_256, _128, _128>;
+  using ClusterShape = Shape<_2, _2, _1>;
+  using Cutlass3xGemm =
+      cutlass_3x_gemm_sm100<InType, OutType, Epilogue, TileShape, ClusterShape,
+                            KernelSchedule, EpilogueSchedule>;
+};
+
+template <typename InType, typename OutType,
+          template <typename, typename, typename> typename Epilogue>
+struct sm100_fp8_config_M256 {
+  // M in (128, 256]
```

**Explanation**:

- Refined the default configuration to target larger matrix dimensions (M > 256) with optimized TileShape increasing K dimension from 64 to 128
- Added new specialized configuration `sm100_fp8_config_M256` for intermediate batch sizes (128 < M <= 256) using smaller tile dimensions (128x128x128)
- The K dimension optimization (64->128 for default, 64->256 for M128) improves memory access patterns and computational efficiency

```diff
@@ -33,8 +47,8 @@ struct sm100_fp8_config_M128 {
   static_assert(std::is_same<InType, cutlass::float_e4m3_t>());
   using KernelSchedule = cutlass::gemm::collective::KernelScheduleAuto;
   using EpilogueSchedule = cutlass::epilogue::collective::EpilogueScheduleAuto;
-  using TileShape = Shape<_128, _128, _64>;
-  using ClusterShape = Shape<_2, _2, _1>;
+  using TileShape = Shape<_128, _128, _256>;
+  using ClusterShape = Shape<_2, _4, _1>;
```

**Explanation**:

- Enhanced M128 configuration with larger K dimension (64->256) and modified cluster shape (2x2x1 -> 2x4x1)
- Cluster shape change increases parallelism in the N dimension, better utilizing SM100's increased compute units
- These parameters are specifically tuned for smaller batch sizes where memory bandwidth is less critical than compute utilization

```diff
@@ -85,8 +101,12 @@ inline void cutlass_gemm_sm100_fp8_dispatch(torch::Tensor& out,
     // m in (64, 128]
     return cutlass_gemm_caller<Cutlass3xGemmM128>(
         out, a, b, std::forward<EpilogueArgs>(args)...);
+  } else if (mp2 <= 256) {
+    // m in (128, 256]
+    return cutlass_gemm_caller<Cutlass3xGemmM256>(
+        out, a, b, std::forward<EpilogueArgs>(args)...);
   } else {
-    // m in (128, inf)
+    // m in (256, inf)
```

**Explanation**:

- Updated dispatch logic to include the new M256 configuration, creating three distinct optimization ranges
- Uses next power of 2 (mp2) for efficient branching and ensures proper kernel selection based on actual matrix dimensions
- The tiered approach allows for fine-grained optimization targeting specific workload characteristics

#### PR Discussion & Comments
**@gemini-code-assist[bot] → @ilmarkov** — Code review feedback on configuration ranges
"Double check that this is the intended range, and that the upper bound is indeed unbounded"

**@gemini-code-assist[bot] → @ilmarkov** — Testing recommendations
"Consider adding a unit test to verify that this config is used when M is 129, 192, and 256"

**@houseroad → @ilmarkov** — Approval from collaborator
"Looks good."

**@mgoin → @ilmarkov** — Appreciation from team member
"Thank you @ilmarkov !"

#### Key Takeaways
- Demonstrates importance of dimension-specific kernel tuning for optimal FP8 performance on modern GPU architectures
- Shows how tile shape and cluster configuration parameters directly impact GEMM performance, with K dimension optimization being particularly effective
- Empirical results validate the optimization strategy: 1.13-1.32x speedup for M=128, up to 1.4x for M=256, and sustained 1.2x improvements for M>=512
- The three-tier configuration approach (M64, M128-M256, M256+) provides a scalable framework for future CUTLASS optimizations

#### Further Reading
- [CUTLASS Documentation](https://github.com/NVIDIA/cutlass) - Official NVIDIA CUTLASS library
- [vLLM Quantization Guide](https://docs.vllm.ai/en/latest/quantization/fp8.html) - FP8 quantization implementation
- [Direct PR Link](https://github.com/vllm-project/vllm/pull/19566) - Complete benchmarks and implementation details