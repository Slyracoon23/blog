---
aliases:
- /vllm-merged-prs-week-june-13-20/
categories:
- Open Source
- Python
- FastAPI
- Performance
date: '2025-07-20'
image: /images/opensource/vllm_merged_prs_week_june_13_20.png
title: "vLLM Merged PRs week (June 13-20)"
subtitle: "A look at the PRs merged to vLLM this week"
format: html
---
# vLLM Merged PRs - Week (June 13-20, 2025)

**Total PRs: 114**

## Summary by Category

- **Bug Fixes**: 28 PRs (24.6%)
- **Miscellaneous & Cleanup**: 21 PRs (18.4%)
- **Performance & Optimization**: 16 PRs (14.0%)
- **Kernel & Hardware**: 12 PRs (10.5%)
- **V1 Engine**: 8 PRs (7.0%)
- **Model Support**: 8 PRs (7.0%)
- **CI/Build**: 7 PRs (6.1%)
- **Frontend & API**: 5 PRs (4.4%)
- **Documentation**: 5 PRs (4.4%)
- **TPU**: 3 PRs (2.6%)
- **Other categories**: 1 PR each

## Key Highlights

1. **Major Focus on Bug Fixes**: Nearly 25% of PRs were bug fixes, showing active maintenance
2. **Performance Improvements**: Significant work on FP4 MOE kernels and CUTLASS optimizations
3. **V1 Engine Development**: Continued development of the new V1 engine architecture
4. **Speculative Decoding Fixes**: Multiple fixes for speculative decoding test stability
5. **Hardware Support**: Updates for TPU, AMD ROCm, and NVIDIA hardware
6. **Code Quality**: Many cleanup and maintenance PRs to improve code quality

--- 

::: {.panel-tabset}

## üêõ Bug Fixes (28 PRs)

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19624: Fix DP Coordinator incorrect debug log message"}
{{< include pr/vllm/pr_19624_dp_coordinator_log_fix.qmd >}}
:::


::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19316: Fix auto dtype casting for BatchFeature"}
{{< include pr/vllm/pr_19316_batchfeature_dtype_fix.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19561: Don't attempt to use triton if no driver is active"}
{{< include pr/vllm/pr_19561_triton_driver_check.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19644: Fix speculative decoding CI - Fix test_ngram_e2e_greedy_correctness"}
{{< include pr/vllm/pr_19644_speculative_decoding_fix.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19633: Fix the speculative decoding test by setting the target dtype"}
{{< include pr/vllm/pr_19633_speculative_dtype_fix.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19561: Don't attempt to use triton if no driver is active"}
{{< include pr/vllm/pr_19561_triton_driver_check.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19262: Convert kv_transfer_config from dict to KVTransferConfig"}
{{< include pr/vllm/pr_19262_kv_transfer_config_fix.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19660: Fix skipped max-model-len validation when deriving max model length from tokenizer config"}
{{< include pr/vllm/pr_19660_max_model_len_validation.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19583: Set the cuda context eagerly in the ray worker"}
{{< include pr/vllm/pr_19583_ray_cuda_context_fix.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19725: Fix RAY_CGRAPH_get_timeout is not set successfully"}
{{< include pr/vllm/pr_19725_ray_cgraph_timeout_fix.qmd >}}
:::

::: {.callout-warning collapse="true" title="üêõ Bug Fix - PR #19872: Fix deadlock on v1 engine test CI"}
{{< include pr/vllm/pr_19872_v1_engine_deadlock_fix.qmd >}}
:::

6. **[#19875](https://github.com/vllm-project/vllm/pull/19875)** - [Fix] import regex instead of re
7. **[#18032](https://github.com/vllm-project/vllm/pull/18032)** - [Benchmark] Fix `Value of type "SampleRequest" is not indexable`
8. **[#19901](https://github.com/vllm-project/vllm/pull/19901)** - [CPU][CI] Fallback sliding window to v0 and fix CPU pooling model tests
9. **[#19589](https://github.com/vllm-project/vllm/pull/19589)** - [CI/Build] Fix torch nightly CI dependencies part 2

## ‚ö° Performance & Optimization (16 PRs)

1. **[#19500](https://github.com/vllm-project/vllm/pull/19500)** - [Hardware][NVIDIA][kernel] Fp4 MOE quant kernel optimization
2. **[#19566](https://github.com/vllm-project/vllm/pull/19566)** - [Perf] Further tunings for SM100 FP8 CUTLASS kernel
3. **[#18777](https://github.com/vllm-project/vllm/pull/18777)** - Export NaNs in logits to scheduler_stats if output is corrupted
4. **[#18354](https://github.com/vllm-project/vllm/pull/18354)** - [V1][Metrics] Deprecate metrics with gpu_ prefix for non GPU specific metrics

## ü§ñ Model Support (8 PRs)

1. **[#19663](https://github.com/vllm-project/vllm/pull/19663)** - [Model] GPT2ForSequenceClassification model

## üèóÔ∏è CI/Build (7 PRs)

1. **[#19508](https://github.com/vllm-project/vllm/pull/19508)** - Adding "AMD: Multi-step Tests" to amdproduction
2. **[#19648](https://github.com/vllm-project/vllm/pull/19648)** - Only build CUTLASS MoE kernels on Hopper
3. **[#19649](https://github.com/vllm-project/vllm/pull/19649)** - [Misc] Remove duplicate multiproc method setting for CPU platform

## üîß Kernel & Hardware (12 PRs)

1. **[#19745](https://github.com/vllm-project/vllm/pull/19745)** - [Kernel] correct cpu worker function parameter type
2. **[#19749](https://github.com/vllm-project/vllm/pull/19749)** - [Kernel] mark TorchSDPABackend swap_blocks NotImplementedError

## üåê Frontend & API (5 PRs)

1. **[#19564](https://github.com/vllm-project/vllm/pull/19564)** - [Misc][Frontend] passthrough `bad_words`

## üìö Documentation (5 PRs)

1. **[#19526](https://github.com/vllm-project/vllm/pull/19526)** - [Misc] update cuda version
2. **[#19851](https://github.com/vllm-project/vllm/pull/19851)** - [Misc] refactor example - openai_transcription_client

## üßπ Miscellaneous & Cleanup (21 PRs)

1. **[#19593](https://github.com/vllm-project/vllm/pull/19593)** - [Misc] Modularize CLI Argument Parsing in Benchmark Scripts
2. **[#19609](https://github.com/vllm-project/vllm/pull/19609)** - [MISC] Remove unused variables in C++
3. **[#19672](https://github.com/vllm-project/vllm/pull/19672)** - [MISC] typo fix
4. **[#19889](https://github.com/vllm-project/vllm/pull/19889)** - [Misc] Clean up useless code

## üöÄ V1 Engine (8 PRs)

1. **[#19164](https://github.com/vllm-project/vllm/pull/19164)** - [custom_op][vllm-plugin] update custom_op class to use op_registry

## üéØ Speculative Decoding (2 PRs)

*Already listed in Bug Fixes section*

## üîß TPU (3 PRs)

1. **[#19620](https://github.com/vllm-project/vllm/pull/19620)** - [TPU] support attention head dim smaller than 128

## üî¥ AMD/ROCm (1 PR)

*Already listed in CI/Build section*

## üõ†Ô∏è Tool Calling (1 PR)

*Already listed in Bug Fixes section*

## üîó Full CUDA Graphs (1 PR)

1. **[#19617](https://github.com/vllm-project/vllm/pull/19617)** - Enable prefix caching with full cuda graphs

:::